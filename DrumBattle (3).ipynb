{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noniin\n",
      "./trainSamplet/drum0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikko/madmom/madmom/audio/cepstrogram.py:202: UserWarning: Spectrogram was filtered or scaled already, redo calculation!\n",
      "  warnings.warn('Spectrogram was filtered or scaled already, redo '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./trainSamplet/drum1.wav\n",
      "./trainSamplet/drum2.wav\n",
      "./trainSamplet/drum3.wav\n",
      "./trainSamplet/drum4.wav\n",
      "./trainSamplet/drum5.wav\n",
      "./trainSamplet/drum6.wav\n",
      "./trainSamplet/drum7.wav\n",
      "./trainSamplet/drum8.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sit aletaan skabaamaan ja soittajan pätkät analysoidaan, muutetaan midiksi ja niistä sit opitaan generoimaan uutta'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import madmom\n",
    "import numpy as np\n",
    "import madmom.audio.cepstrogram\n",
    "from madmom.audio.filters import MelFilterbank\n",
    "from madmom.audio.filters import RectangularFilterbank\n",
    "from sklearn.decomposition import PCA, FastICA, NMF\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import pyaudio\n",
    "import time\n",
    "import scipy\n",
    "\n",
    "FRAME_SIZE=2**11\n",
    "HOP_SIZE=2**9\n",
    "SAMPLE_RATE=44100\n",
    "FREQUENCY_PRE=np.ones((24))#[0,16384]#0-2^14\n",
    "MIDINOTE=36 #kickdrum in most systems\n",
    "THRESHOLD=0.0 \n",
    "PROBABILITY_THRESHOLD=0.0\n",
    "DRUMKIT_PATH='./trainSamplet/'\n",
    "midinotes=[36,38,42,46,50,43,51,49,44] #BD, SN, CHH, OHH, TT, FT, RD, CR, SHH\n",
    "\n",
    "proc=madmom.audio.filters.BarkFilterbank(madmom.audio.stft.fft_frequencies(num_fft_bins=int(FRAME_SIZE/2), sample_rate=SAMPLE_RATE) ,num_bands='double')\n",
    "#proc=madmom.audio.filters.LogarithmicFilterbank(num_bands=24)\n",
    "class Drum(object):\n",
    "    \"\"\"\n",
    "    A Drum is any user playable drumkit part representation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : String\n",
    "        Name of the drum\n",
    "    frequency_pre : list, optional\n",
    "        corner frequencies of drum signal\n",
    "    midinote: int, optional\n",
    "        midi note representing the drum\n",
    "    threshold : float, optional\n",
    "        onset detection threshold.\n",
    "    probability_threshold : float, optional\n",
    "        NN prediction threshold.\n",
    "    \n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Unfinished class, work in progress\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, name,highEmph,peaks, samples=None,templates=None, frequency_pre=FREQUENCY_PRE,\n",
    "                 midinote=MIDINOTE, threshold=THRESHOLD, probability_threshold=PROBABILITY_THRESHOLD\n",
    "                 ,**kwargs):\n",
    "        \n",
    "        # set attributes\n",
    "        self.name = name\n",
    "        self.highEmph=highEmph\n",
    "        self.peaks=peaks\n",
    "        if len(frequency_pre):\n",
    "            self.frequency_pre = frequency_pre\n",
    "        if len(samples):\n",
    "            self.samples = samples\n",
    "        if len(templates):\n",
    "            self.templates=templates\n",
    "        if midinote:\n",
    "            self.midinote=midinote\n",
    "        if threshold:\n",
    "            self.threshold = float(threshold)\n",
    "        if probability_threshold:\n",
    "            self.probability_threshold=float(probability_threshold)\n",
    "    def set_name(self,name):\n",
    "        self.name=name\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    def set_highEmph(self,highEmph):\n",
    "        self.highEmph=highEmph\n",
    "    def get_highEmph(self):\n",
    "        return self.highEmph\n",
    "    def set_peaks(self,name):\n",
    "        self.name=peaks\n",
    "    def get_peaks(self):\n",
    "        return self.peaks\n",
    "    def set_templates(self,templates):\n",
    "        self.templates=templates\n",
    "    def get_templates(self):\n",
    "        return self.templates \n",
    "    def set_samples(self,samples):\n",
    "        self.samples=samples\n",
    "    def get_samples(self):\n",
    "        return self.samples\n",
    "    def set_frequency_pre(self,frequency_pre):\n",
    "        self.frequency_pre=frequency_pre\n",
    "    def get_frequency_pre(self):\n",
    "        return self.frequency_pre  \n",
    "    def set_midinote(self,midinote):\n",
    "        self.midinote=int(midinote)\n",
    "    def get_midinote(self):\n",
    "        return self.midinote\n",
    "    def set_threshold(self,threshold):\n",
    "        self.threshold=float(threshold)\n",
    "    def get_threshold(self):\n",
    "        return self.threshold\n",
    "    def set_probability_threshold(self,probability_threshold):\n",
    "        self.probability_threshold=float(probability_threshold)\n",
    "    def get_probability_threshold(self):\n",
    "        return self.probability_threshold\n",
    "\n",
    "#live audio\n",
    "print('noniin')\n",
    "\n",
    "#From https://stackoverflow.com/questions/24354279/python-spectral-centroid-for-a-wav-file\n",
    "def spectral_centroid(x, samplerate=44100):\n",
    "    magnitudes = np.abs(np.fft.rfft(x)) # magnitudes of positive frequencies\n",
    "    length = len(x)\n",
    "    freqs = np.abs(np.fft.fftfreq(length, 1.0/samplerate)[:length//2+1]) # positive frequencies\n",
    "    return np.log(np.sum(magnitudes*freqs) / np.sum(magnitudes))\n",
    "def ZCR(signal):\n",
    "    ZC=0\n",
    "    for i in range(1,signal.shape[0]):\n",
    "        if np.sign(signal[i-1])!=np.sign(signal[i]):\n",
    "            ZC+=1\n",
    "    return ZC\n",
    "#brickwall limiter to even out high peaks\n",
    "def limitToPercentile(data, limit=90, lowlimit=10, ratio=1):\n",
    "    limit=np.percentile(data,limit)\n",
    "    lowlimit=np.percentile(data,lowlimit)\n",
    "    highPeaks = abs(data) > limit # Where values higher than the percentile\n",
    "    data[highPeaks] = limit #brickwall the signal to the limit\n",
    "    lowPeaks = abs(data) < lowlimit # Where values higher than the percentile\n",
    "    data[lowPeaks] = np.sign(data[lowPeaks])*lowlimit #brickwall the signal to the limit\n",
    "    return (data)\n",
    "def cleanDoubleStrokes(hitList, resolution=10):\n",
    "        retList=[]\n",
    "        lastSeenHit=0\n",
    "        for i in range(len(hitList)):\n",
    "            if hitList[i]>=lastSeenHit+resolution:\n",
    "                retList.append(hitList[i])\n",
    "                lastSeenHit=hitList[i]\n",
    "        return (np.array(retList))\n",
    "##Pitäiskö laittaa toi gäppi kans määriteltäväksi??    \n",
    "def filter_emphasis(spectro,highEmph):\n",
    "    #Otetaan hetkeksi pois käytöstä\n",
    "    return spectro\n",
    "    dummy=np.zeros_like(spectro)\n",
    "\n",
    "    if(highEmph==-1):\n",
    "        dummy[:,:5]=spectro[:,:5]\n",
    "    elif(highEmph==0):\n",
    "        dummy[:,2:7]=spectro[:,2:7]\n",
    "    elif(highEmph==1):\n",
    "        dummy[:,-5:]=spectro[:,-5:]\n",
    "    elif(highEmph==2):\n",
    "        dummy=spectro\n",
    "        \n",
    "    return dummy\n",
    "\n",
    "def muLaw(Y, mu=10**8):\n",
    "    #n=frames, i=sub-bands\n",
    "    x_mu=np.zeros_like(Y)\n",
    "\n",
    "    for n in range(Y.shape[0]):\n",
    "        for i in range(Y.shape[1]):\n",
    "            #x_i_n=Y[n,i].flatten()@Y[n,i].flatten()\n",
    "            x_i_n=Y[n,i]\n",
    "            x_mu[n,i]= np.sign(Y[n,i]) * np.log(1 + mu * x_i_n)/np.log(1 + mu)\n",
    "    return x_mu\n",
    "\n",
    "def get_preprocessed_spectrogram(buffer):\n",
    "    buffer=buffer/max(buffer)\n",
    "    buffer=madmom.audio.FramedSignal(buffer,sample_rate=SAMPLE_RATE,frame_size=FRAME_SIZE, hop_size=HOP_SIZE)\n",
    "    spec=madmom.audio.spectrogram.FilteredSpectrogram(buffer, filterbank=proc, sample_rate=SAMPLE_RATE,frame_size=FRAME_SIZE, hop_size=HOP_SIZE, fmin=20)\n",
    "    #spec=muLaw(spec,mu=10**8)\n",
    "    spec=spec/spec.max()\n",
    "    return spec\n",
    "\n",
    "#Too hard coded method- refine generality\n",
    "def generate_features(signal, highEmph):\n",
    "    features=[]\n",
    "    try:    \n",
    "        #fiba=madmom.audio.spectrogram.FilteredSpectrogram(signal,filterbank=proc,sample_rate=44100, f_min=10)\n",
    "        fiba=get_preprocessed_spectrogram(signal)\n",
    "        fiba2=filter_emphasis(fiba, highEmph)\n",
    "        mfcc2=madmom.audio.cepstrogram.MFCC(fiba2, num_bands=32)\n",
    "        mfcc_delta = librosa.feature.delta(mfcc2)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc2, order=2)\n",
    "\n",
    "        feats=np.append(mfcc2[0],[mfcc2[1]\n",
    "                                  ,mfcc2[2]\n",
    "                                  ,mfcc2[3]\n",
    "                                  , mfcc_delta[0]\n",
    "                                  , mfcc_delta[1]])\n",
    "        features=(np.append(feats,[np.append([ZCR(signal)]\n",
    "                                                   , [np.append([scipy.stats.kurtosis(signal)]\n",
    "                                                        ,[np.append([scipy.stats.skew(signal)]\n",
    "                                                            ,[spectral_centroid(signal)])])])])) \n",
    "        \n",
    "    except Exception as e:\n",
    "        print('feature error:',e)\n",
    "        \"\"\"muista panna paddia alkuun ja loppuun\"\"\" \n",
    "        \n",
    "    return features\n",
    "def make_sample(signal, time, n_frames):\n",
    "    sample=madmom.audio.signal.signal_frame(signal,time, frame_size=n_frames*HOP_SIZE, hop_size=HOP_SIZE, origin=0)\n",
    "    sample=madmom.audio.signal.normalize(sample)\n",
    "    return sample\n",
    "\n",
    "def add_to_samples_and_dictionary(drum, signal, times):\n",
    "    for i in times:\n",
    "        sample=make_sample(signal, i,n_frames=4)\n",
    "        drum.get_samples().append(sample)\n",
    "        drum.get_templates().append(generate_features(sample, drum.get_highEmph()))\n",
    "        \n",
    "def getPeaksFromBuffer(buffer, resolution, numHits, highEmph=0):\n",
    "    \n",
    "    filt_spec=get_preprocessed_spectrogram(buffer)\n",
    "    \n",
    "    def findDefBins(frames, filteredSpec):\n",
    "        gaps=np.zeros(frames.shape[0]*10)\n",
    "        \n",
    "        n_frames=4\n",
    "        for i in range(frames.shape[0]):\n",
    "            \n",
    "            gaps[(i*n_frames)]=frames[i]\n",
    "            gaps[(i*n_frames)+1]=frames[i]+1\n",
    "            gaps[(i*n_frames)+2]=frames[i]+2\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "        heads=np.mean(filteredSpec[gaps.astype(int)].T, axis=1)\n",
    "        #from sklearn.mixture import GaussianMixture\n",
    "        #GM=GaussianMixture(n_components=1)\n",
    "        #GM.fit(filteredSpec[frames])\n",
    "        #heads=GM.means_\n",
    "        tailgaps=np.ones(filteredSpec.shape[0])\n",
    "        tailgaps[gaps.astype(int)]=0\n",
    "\n",
    "        tails=(np.mean(filteredSpec[tailgaps==1].T, axis=1))\n",
    "        #tails=(np.mean(filteredSpec[tailgaps.astype(int)].T, axis=1))\n",
    "        return(heads, tails)\n",
    "        #heads=np.mean(filteredSpec.T, axis=1)\n",
    "        #return(heads, tails)\n",
    "        #return(np.mean(filteredSpec[gaps.astype(int)].T, axis=1),np.mean(filteredSpec[-gaps.astype(int)].T, axis=1))\n",
    "    \n",
    "    superflux_3 = madmom.features.onsets.superflux(filt_spec)\n",
    "    superflux_3=superflux_3/(superflux_3.max(axis=0) )\n",
    "    \n",
    "    threshold=1\n",
    "    searchSpeed=0.2\n",
    "    peaks=cleanDoubleStrokes(madmom.features.onsets.peak_picking(superflux_3,threshold),resolution)\n",
    "    \n",
    "    while(peaks.shape!=(numHits,)):\n",
    "        #Make sure we don't go over numHits\n",
    "        #There is a chance of an infinite loop here!!! Make sure that don't happen\n",
    "        if(peaks.shape[0]>numHits):\n",
    "            threshold+=searchSpeed\n",
    "            searchSpeed=searchSpeed/2\n",
    "        threshold-=searchSpeed\n",
    "        peaks=cleanDoubleStrokes(madmom.features.onsets.peak_picking(superflux_3,threshold),resolution)\n",
    "\n",
    "    definingBins=findDefBins(peaks,filt_spec)\n",
    "    return peaks, definingBins, threshold\n",
    "    #return peaks, np.zeros(24), threshold\n",
    "    \n",
    "def playSample(data):\n",
    "    # instantiate PyAudio (1)\n",
    "    p = pyaudio.PyAudio()\n",
    "    # open stream (2)\n",
    "    stream = p.open(format=pyaudio.paFloat32,\n",
    "                    frames_per_buffer=HOP_SIZE,\n",
    "                    channels=1,\n",
    "                    rate=44100,\n",
    "                    output=True)\n",
    "    # play stream (3)\n",
    "    f=0\n",
    "    print(len(data))\n",
    "    while data!='':\n",
    "        stream.write(data[f])\n",
    "        f+=1\n",
    "        if f>=len(data):\n",
    "            break\n",
    "\n",
    "    # stop stream (4)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    \n",
    "    # close PyAudio (5)\n",
    "    p.terminate()\n",
    "\n",
    "def getStompTemplate(numHits=2, recordingLength=1, highEmph=0):\n",
    "    \"\"\"\n",
    "    Kutsutaan pari kertaa, eka vaikka kaks ja sit neljä iskua talteen\n",
    "    Niiden pohjalta lasketaan olennaisin taajuus ja threshold\n",
    "    \"\"\"\n",
    "    stompResolution=1\n",
    "    buffer=np.zeros(shape=(227792*recordingLength))\n",
    "    j=0\n",
    "    strm=madmom.audio.signal.Stream(sample_rate=44100, num_channels=1,frame_size=2048, hop_size=HOP_SIZE)\n",
    "    for i in strm:\n",
    "            #print(i.shape)\n",
    "            buffer[j:j+HOP_SIZE]=i[:HOP_SIZE]\n",
    "            j+=HOP_SIZE\n",
    "            if j>=221792*recordingLength:\n",
    "                buffer[j:j+6000]=np.zeros(6000)\n",
    "                #buffer=madmom.audio.signal.normalize(buffer)\n",
    "                peaks, bins, threshold=getPeaksFromBuffer(buffer, stompResolution,numHits, highEmph=highEmph) \n",
    "                \n",
    "                strm.close()\n",
    "                return peaks, bins,threshold, buffer\n",
    "            \n",
    "\n",
    "\"\"\"Jotain tähän tyyliin sitten sämplejä talteen\"\"\"\n",
    "nrOfDrums=9\n",
    "nrOfPeaks=32\n",
    "fpr=np.zeros((proc.shape[1], nrOfDrums*2))\n",
    "#frames=np.zeros((8192,nrOfDrums*nrOfPeaks))\n",
    "drums=[]\n",
    "list_X=[]\n",
    "list_y=[]\n",
    "#NoneTemplates=[]\n",
    "highEmph=[0,0,0,1,0,0,1,1,0]\n",
    "#highEmph=[2,2,2,2,2,2,2,2,2]\n",
    "###Tässä pitää napata talteen framet/sample\n",
    "for i in range(nrOfDrums):\n",
    "    try:\n",
    "        soundcheck=False\n",
    "        print(\"{}drum{}.wav\".format(DRUMKIT_PATH,i))\n",
    "        buffer=madmom.audio.Signal(\"{}drum{}.wav\".format(DRUMKIT_PATH,i),frame_size=2048, hop_size=HOP_SIZE)\n",
    "        CC1, freqtemps, threshold=getPeaksFromBuffer(buffer,1,nrOfPeaks,highEmph=highEmph[i])\n",
    "        fpr[:,i]=freqtemps[0]\n",
    "        fpr[:,i+nrOfDrums]=freqtemps[1]\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        print('samples not found, please soundcheck!')\n",
    "        print(\"Play drum nr. {}\".format(i+1))\n",
    "        CC1, freqtemps, threshold, buffer= getStompTemplate(nrOfPeaks,recordingLength=2,highEmph=highEmph[i]) \n",
    "        #outBuffer=unFrameSignal(buffer)\n",
    "        madmom.io.audio.write_wave_file(buffer, './drum{}.wav'.format(i),sample_rate=44100)\n",
    "        \n",
    "    if(True):\n",
    "        templates=[]\n",
    "        samples=[]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for j in range(len(CC1)):\n",
    "            \n",
    "            time=CC1[j]\n",
    "            \n",
    "            tinyBuff=make_sample(buffer, time, n_frames=4)\n",
    "            templates.append(generate_features(tinyBuff, highEmph[i]))\n",
    "        \n",
    "            samples.append(tinyBuff)\n",
    "            \n",
    "        drums.append(Drum(name=[i], highEmph=highEmph[i], peaks=CC1,templates=templates, samples=samples, threshold=threshold, midinote=midinotes[i], probability_threshold=1))\n",
    "\n",
    "'''generate artificial samples where multiple drums are hit at the same time, store as Drum objects'''\n",
    "\n",
    "def generateNewSample(drums):\n",
    "    samplesA=drums[0].get_samples()\n",
    "    samplesB=drums[1].get_samples()\n",
    "    samplesC=[]\n",
    "    for i in range(min([len(samplesA), len(samplesB)])):\n",
    "        samplesC.append((.5*samplesA[i])+(.5*samplesB[i]))\n",
    "    samplesC=np.array(samplesC)\n",
    "  \n",
    "    templatesC=[]\n",
    "    highEmphA=drums[0].get_highEmph()\n",
    "    highEmphB=drums[1].get_highEmph()\n",
    "    if highEmphA==highEmphB:\n",
    "        for j in range(len(samplesC)):\n",
    "            templatesC.append(generate_features(samplesC[j], highEmph))\n",
    "            \n",
    "    #Jos ei highemph täsmää tehdään puolet toista ja puolet toista.        \n",
    "    else:\n",
    "        for j in range(int(len(samplesC)/2)):\n",
    "            templatesC.append(generate_features(samplesC[j], highEmphA))\n",
    "            templatesC.append(generate_features(samplesC[-j], highEmphB))\n",
    "            \n",
    "    return Drum([drums[0].get_name(),drums[1].get_name()],0, None,templates=templatesC, samples=[], midinote=[])  \n",
    "\n",
    "from itertools import combinations, permutations\n",
    "newDrums=combinations(drums[:nrOfDrums], 2)\n",
    "for i in newDrums:\n",
    "    drums.append(generateNewSample(i))\n",
    "    \n",
    "#try:\n",
    "#        \n",
    "#    soundcheck=False\n",
    "#    buffer=madmom.audio.Signal(\"{}drumBeat.wav\".format(DRUMKIT_PATH),frame_size=2048, hop_size=HOP_SIZE)\n",
    "#    \n",
    "#except:\n",
    "#    print('samples not found, please soundcheck!')\n",
    "#    print(\"Play a drum beat\")\n",
    "#    CC1, frequencies, threshold, buffer= getStompTemplate(nrOfPeaks,recordingLength=4,highEmph=-1) \n",
    "#    madmom.io.audio.write_wave_file(buffer, '{}drumBeat.wav'.format(DRUMKIT_PATH),sample_rate=44100)\n",
    "#    print('joo joo, voit lopettaa jo')\n",
    "#\n",
    "    \n",
    "### tee list_X ja list_y täsä drumseista.\n",
    "\n",
    "for i in drums:\n",
    "    #one for every template the drum has stored\n",
    "    for j in i.get_templates():\n",
    "        #one for every drum present in the template\n",
    "        a=np.ravel(i.get_name())\n",
    "        for k in range(len(a)):\n",
    "            list_X.append(j)\n",
    "            list_y.append(a[k])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##Classify all the templates so that precision is 1, and set the PROBABILITY_THRESHOLD accordingly.\n",
    "\n",
    "'''Tänne generator NN keras, joka oppii sitä mukaa ku roinaa tulee'''\n",
    "'''Eka opetellaan haitsun poljenta joka toimii käyttöliittymän osana'''\n",
    "'''Sit eri rummut'''\n",
    "'''Sit aletaan skabaamaan ja soittajan pätkät analysoidaan, muutetaan midiksi ja niistä sit opitaan generoimaan uutta'''\n",
    "\n",
    "#Tää jäi siihen että sai jotenkuten sn,bd,hh eroamaan, mutta jotain mätää on filttereissä kun basari ja snare on melkein samaa aaltoa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikko/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16384, 196)\n",
      "(16384, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(196, input_shape=(196,), kernel_initializer=\"he_normal\")`\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(98, activation=\"relu\", kernel_initializer=\"he_normal\")`\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(49, activation=\"relu\", kernel_initializer=\"lecun_uniform\")`\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(9, activation=\"softmax\", kernel_initializer=\"lecun_uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 196)               38612     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 196)               784       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 98)                19306     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 98)                392       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 49)                4851      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 49)                196       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 450       \n",
      "=================================================================\n",
      "Total params: 64,591\n",
      "Trainable params: 63,905\n",
      "Non-trainable params: 686\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 14745 samples, validate on 1639 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.8884 - acc: 0.3228 - val_loss: 1.3633 - val_acc: 0.5082\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.36331, saving model to weights_testivedot.hdf5\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.3862 - acc: 0.4913 - val_loss: 1.1153 - val_acc: 0.5229\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.36331 to 1.11532, saving model to weights_testivedot.hdf5\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.2053 - acc: 0.5241 - val_loss: 1.0067 - val_acc: 0.5320\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.11532 to 1.00674, saving model to weights_testivedot.hdf5\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.1135 - acc: 0.5394 - val_loss: 0.9874 - val_acc: 0.5369\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.00674 to 0.98742, saving model to weights_testivedot.hdf5\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1.0607 - acc: 0.5387 - val_loss: 0.9016 - val_acc: 0.5607\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.98742 to 0.90158, saving model to weights_testivedot.hdf5\n",
      "Epoch 6/100\n",
      " - 0s - loss: 1.0117 - acc: 0.5433 - val_loss: 0.8554 - val_acc: 0.5516\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.90158 to 0.85543, saving model to weights_testivedot.hdf5\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.9753 - acc: 0.5493 - val_loss: 0.8238 - val_acc: 0.5558\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.85543 to 0.82385, saving model to weights_testivedot.hdf5\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.9421 - acc: 0.5472 - val_loss: 0.7786 - val_acc: 0.5540\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.82385 to 0.77855, saving model to weights_testivedot.hdf5\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.9039 - acc: 0.5581 - val_loss: 0.7866 - val_acc: 0.5705\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.77855\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.8883 - acc: 0.5558 - val_loss: 0.7816 - val_acc: 0.5638\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.77855\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.8702 - acc: 0.5593 - val_loss: 0.7440 - val_acc: 0.5778\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.77855 to 0.74403, saving model to weights_testivedot.hdf5\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.8529 - acc: 0.5604 - val_loss: 0.7251 - val_acc: 0.5741\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.74403 to 0.72513, saving model to weights_testivedot.hdf5\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.8328 - acc: 0.5613 - val_loss: 0.7267 - val_acc: 0.5619\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.72513\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.8214 - acc: 0.5597 - val_loss: 0.7163 - val_acc: 0.5711\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.72513 to 0.71627, saving model to weights_testivedot.hdf5\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.8108 - acc: 0.5613 - val_loss: 0.7050 - val_acc: 0.5644\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.71627 to 0.70500, saving model to weights_testivedot.hdf5\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.7883 - acc: 0.5703 - val_loss: 0.7008 - val_acc: 0.5686\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.70500 to 0.70075, saving model to weights_testivedot.hdf5\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.7851 - acc: 0.5651 - val_loss: 0.6868 - val_acc: 0.5607\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.70075 to 0.68678, saving model to weights_testivedot.hdf5\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.7759 - acc: 0.5675 - val_loss: 0.6936 - val_acc: 0.5869\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.68678\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.7678 - acc: 0.5674 - val_loss: 0.6809 - val_acc: 0.5668\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.68678 to 0.68092, saving model to weights_testivedot.hdf5\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.7618 - acc: 0.5657 - val_loss: 0.6728 - val_acc: 0.5699\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.68092 to 0.67285, saving model to weights_testivedot.hdf5\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.7586 - acc: 0.5624 - val_loss: 0.6666 - val_acc: 0.5656\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.67285 to 0.66656, saving model to weights_testivedot.hdf5\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.7450 - acc: 0.5745 - val_loss: 0.6707 - val_acc: 0.5680\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.66656\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.7411 - acc: 0.5683 - val_loss: 0.6689 - val_acc: 0.5723\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.66656\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.7355 - acc: 0.5746 - val_loss: 0.6712 - val_acc: 0.5833\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.66656\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.7314 - acc: 0.5746 - val_loss: 0.6652 - val_acc: 0.5625\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.66656 to 0.66518, saving model to weights_testivedot.hdf5\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.7302 - acc: 0.5685 - val_loss: 0.6610 - val_acc: 0.5650\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.66518 to 0.66104, saving model to weights_testivedot.hdf5\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.7223 - acc: 0.5767 - val_loss: 0.6512 - val_acc: 0.5815\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.66104 to 0.65117, saving model to weights_testivedot.hdf5\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.7163 - acc: 0.5780 - val_loss: 0.6557 - val_acc: 0.5625\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.65117\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.7167 - acc: 0.5727 - val_loss: 0.6647 - val_acc: 0.5711\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.65117\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.7112 - acc: 0.5742 - val_loss: 0.6535 - val_acc: 0.5686\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.65117\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.7151 - acc: 0.5658 - val_loss: 0.6601 - val_acc: 0.5680\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.65117\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.7094 - acc: 0.5738 - val_loss: 0.6479 - val_acc: 0.5613\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.65117 to 0.64793, saving model to weights_testivedot.hdf5\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.7068 - acc: 0.5759 - val_loss: 0.6511 - val_acc: 0.5509\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.64793\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.7007 - acc: 0.5784 - val_loss: 0.6531 - val_acc: 0.5613\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.64793\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.6997 - acc: 0.5746 - val_loss: 0.6625 - val_acc: 0.5509\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.64793\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.6977 - acc: 0.5707 - val_loss: 0.6487 - val_acc: 0.5619\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.64793\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.6929 - acc: 0.5830 - val_loss: 0.6515 - val_acc: 0.5650\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.64793\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.6936 - acc: 0.5740 - val_loss: 0.6371 - val_acc: 0.5558\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.64793 to 0.63709, saving model to weights_testivedot.hdf5\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.6940 - acc: 0.5752 - val_loss: 0.6401 - val_acc: 0.5601\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.63709\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.6873 - acc: 0.5776 - val_loss: 0.6440 - val_acc: 0.5570\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.63709\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.6828 - acc: 0.5829 - val_loss: 0.6353 - val_acc: 0.5772\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.63709 to 0.63535, saving model to weights_testivedot.hdf5\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.6813 - acc: 0.5811 - val_loss: 0.6455 - val_acc: 0.5723\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.63535\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.6817 - acc: 0.5766 - val_loss: 0.6381 - val_acc: 0.5601\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.63535\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.6804 - acc: 0.5821 - val_loss: 0.6397 - val_acc: 0.5534\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.63535\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.6840 - acc: 0.5748 - val_loss: 0.6403 - val_acc: 0.5607\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.63535\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.6893 - acc: 0.5797 - val_loss: 0.6442 - val_acc: 0.5558\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.63535\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.6836 - acc: 0.5744 - val_loss: 0.6450 - val_acc: 0.5497\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.63535\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.6809 - acc: 0.5707 - val_loss: 0.6355 - val_acc: 0.5760\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.63535\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.6750 - acc: 0.5796 - val_loss: 0.6351 - val_acc: 0.5570\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.63535 to 0.63509, saving model to weights_testivedot.hdf5\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.6767 - acc: 0.5765 - val_loss: 0.6396 - val_acc: 0.5479\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.63509\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.6773 - acc: 0.5783 - val_loss: 0.6351 - val_acc: 0.5607\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.63509\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.6751 - acc: 0.5706 - val_loss: 0.6329 - val_acc: 0.5711\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.63509 to 0.63293, saving model to weights_testivedot.hdf5\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.6761 - acc: 0.5789 - val_loss: 0.6378 - val_acc: 0.5650\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.63293\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.6711 - acc: 0.5815 - val_loss: 0.6343 - val_acc: 0.5631\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.63293\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.6714 - acc: 0.5821 - val_loss: 0.6316 - val_acc: 0.5723\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.63293 to 0.63159, saving model to weights_testivedot.hdf5\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.6703 - acc: 0.5881 - val_loss: 0.6413 - val_acc: 0.5613\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.63159\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.6713 - acc: 0.5778 - val_loss: 0.6437 - val_acc: 0.5711\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.63159\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.6722 - acc: 0.5765 - val_loss: 0.6319 - val_acc: 0.5796\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.63159\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.6685 - acc: 0.5822 - val_loss: 0.6393 - val_acc: 0.5650\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.63159\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.6635 - acc: 0.5828 - val_loss: 0.6345 - val_acc: 0.5754\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.63159\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.6649 - acc: 0.5850 - val_loss: 0.6290 - val_acc: 0.5766\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.63159 to 0.62905, saving model to weights_testivedot.hdf5\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.6648 - acc: 0.5811 - val_loss: 0.6327 - val_acc: 0.5638\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.62905\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.6651 - acc: 0.5824 - val_loss: 0.6363 - val_acc: 0.5650\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.62905\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.6641 - acc: 0.5806 - val_loss: 0.6314 - val_acc: 0.5613\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.62905\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.6636 - acc: 0.5828 - val_loss: 0.6351 - val_acc: 0.5595\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.62905\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.6617 - acc: 0.5828 - val_loss: 0.6321 - val_acc: 0.5625\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.62905\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.6579 - acc: 0.5899 - val_loss: 0.6397 - val_acc: 0.5546\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.62905\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.6588 - acc: 0.5841 - val_loss: 0.6297 - val_acc: 0.5662\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.62905\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.6667 - acc: 0.5760 - val_loss: 0.6337 - val_acc: 0.5631\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.62905\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.6609 - acc: 0.5835 - val_loss: 0.6297 - val_acc: 0.5607\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.62905\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.6603 - acc: 0.5817 - val_loss: 0.6310 - val_acc: 0.5650\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.62905\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.6565 - acc: 0.5839 - val_loss: 0.6343 - val_acc: 0.5692\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.62905\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.6606 - acc: 0.5807 - val_loss: 0.6276 - val_acc: 0.5638\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.62905 to 0.62762, saving model to weights_testivedot.hdf5\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.6568 - acc: 0.5867 - val_loss: 0.6327 - val_acc: 0.5583\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.62762\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.6581 - acc: 0.5815 - val_loss: 0.6320 - val_acc: 0.5448\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.62762\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.6574 - acc: 0.5864 - val_loss: 0.6391 - val_acc: 0.5638\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.62762\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.6609 - acc: 0.5803 - val_loss: 0.6279 - val_acc: 0.5790\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.62762\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.6579 - acc: 0.5843 - val_loss: 0.6346 - val_acc: 0.5613\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.62762\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.6548 - acc: 0.5820 - val_loss: 0.6395 - val_acc: 0.5448\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.62762\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.6589 - acc: 0.5839 - val_loss: 0.6346 - val_acc: 0.5479\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.62762\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.6573 - acc: 0.5849 - val_loss: 0.6302 - val_acc: 0.5534\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.62762\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.6541 - acc: 0.5846 - val_loss: 0.6273 - val_acc: 0.5570\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.62762 to 0.62730, saving model to weights_testivedot.hdf5\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.6545 - acc: 0.5866 - val_loss: 0.6355 - val_acc: 0.5497\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.62730\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.6562 - acc: 0.5807 - val_loss: 0.6374 - val_acc: 0.5436\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.62730\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.6555 - acc: 0.5852 - val_loss: 0.6339 - val_acc: 0.5631\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.62730\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.6530 - acc: 0.5861 - val_loss: 0.6284 - val_acc: 0.5711\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.62730\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.6531 - acc: 0.5826 - val_loss: 0.6288 - val_acc: 0.5802\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.62730\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.6560 - acc: 0.5858 - val_loss: 0.6305 - val_acc: 0.5729\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.62730\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.6505 - acc: 0.5830 - val_loss: 0.6268 - val_acc: 0.5656\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.62730 to 0.62685, saving model to weights_testivedot.hdf5\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.6508 - acc: 0.5863 - val_loss: 0.6298 - val_acc: 0.5455\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.62685\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.6541 - acc: 0.5814 - val_loss: 0.6319 - val_acc: 0.5375\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.62685\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.6510 - acc: 0.5855 - val_loss: 0.6323 - val_acc: 0.5503\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.62685\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.6509 - acc: 0.5821 - val_loss: 0.6293 - val_acc: 0.5528\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.62685\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.6500 - acc: 0.5878 - val_loss: 0.6297 - val_acc: 0.5680\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.62685\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.6519 - acc: 0.5795 - val_loss: 0.6284 - val_acc: 0.5680\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.62685\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.6507 - acc: 0.5837 - val_loss: 0.6250 - val_acc: 0.5656\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.62685 to 0.62503, saving model to weights_testivedot.hdf5\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.6500 - acc: 0.5810 - val_loss: 0.6310 - val_acc: 0.5528\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.62503\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.6468 - acc: 0.5890 - val_loss: 0.6282 - val_acc: 0.5674\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.62503\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.6466 - acc: 0.5925 - val_loss: 0.6319 - val_acc: 0.5613\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.62503\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.6482 - acc: 0.5809 - val_loss: 0.6251 - val_acc: 0.5723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00100: val_loss did not improve from 0.62503\n",
      "Loaded model from disk\n",
      "Model saved to disk.\n",
      "Model buiding time:14.80\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from keras.optimizers import sgd as SGD\n",
    "#from keras.layers.advanced_activations import ELU\n",
    "#from keras.utils import np_utils\n",
    "from keras.layers import Convolution2D, Convolution1D, GRU, LSTM,BatchNormalization\n",
    "#from keras.layers import MaxPooling2D, MaxPooling1D, AveragePooling2D\n",
    "#from keras.layers import Flatten, Input\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "#import librosa as lb\n",
    "#from os import listdir\n",
    "#import lightgbm as lgb\n",
    "#import pickle\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "\n",
    "n_samples=2**14\n",
    "\n",
    "\n",
    "X,y=resample(np.array(list_X),np.array(list_y), n_samples=n_samples)\n",
    "\n",
    "scaler=preprocessing.MinMaxScaler()\n",
    "X_train=scaler.fit_transform(X)\n",
    "\n",
    "y_train=y\n",
    "\n",
    "y_train=keras.utils.np_utils.to_categorical(y_train)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "num_labels = y_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(196, input_shape=(X_train.shape[1],), init='he_normal'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense((98), init='he_normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(49, init='lecun_uniform', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_labels, init='lecun_uniform', activation=\"softmax\"))\n",
    "print(model.summary())\n",
    "\n",
    "t0=time()\n",
    "modelsaver=ModelCheckpoint(filepath=\"weights_testivedot.hdf5\", verbose=1, save_best_only=True)\n",
    "earlystopper=EarlyStopping(monitor=\"val_loss\", patience=20, mode='auto')\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='nadam')\n",
    "model.fit(X_train, y_train,batch_size=1024, epochs=100\n",
    "          , callbacks=[modelsaver,earlystopper]\n",
    "          ,validation_split=0.1\n",
    "          ,verbose=2)\n",
    "model.load_weights(\"weights_testivedot.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    "model.save('keras.model_testivedot.h5')\n",
    "cnn=model\n",
    "print('Model saved to disk.')\n",
    "print ('Model buiding time:%0.2f' %(time()-t0))\n",
    "t0=time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikko/.local/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9230769230769231\n",
      "0.8633093525179856\n",
      "0.8921933085501859\n",
      "120.0\n",
      "\n",
      "\n",
      "0.968503937007874\n",
      "0.8978102189781022\n",
      "0.9318181818181818\n",
      "123.0\n",
      "\n",
      "\n",
      "0.2\n",
      "0.17777777777777778\n",
      "0.18823529411764706\n",
      "8.0\n",
      "\n",
      "\n",
      "0.2839506172839506\n",
      "0.5111111111111111\n",
      "0.3650793650793651\n",
      "23.0\n",
      "\n",
      "\n",
      "0.3877551020408163\n",
      "0.2714285714285714\n",
      "0.319327731092437\n",
      "19.0\n",
      "\n",
      "\n",
      "0.6440677966101694\n",
      "0.8085106382978723\n",
      "0.7169811320754716\n",
      "38.0\n",
      "\n",
      "\n",
      "0.34375\n",
      "0.28205128205128205\n",
      "0.3098591549295775\n",
      "22.0\n",
      "\n",
      "\n",
      "0.10869565217391304\n",
      "0.17857142857142858\n",
      "0.13513513513513511\n",
      "5.0\n",
      "\n",
      "\n",
      "0.14285714285714285\n",
      "0.5555555555555556\n",
      "0.22727272727272727\n",
      "10.0\n",
      "\n",
      "\n",
      "Precision: 0.6138582534948634\n",
      "Recall: 0.6062602965403624\n",
      "F-score: 0.6007708102218288\n",
      "done!\n",
      "Processing time:3.73\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from madmom.audio.filters import RectangularFilterbank\n",
    "from scipy.ndimage.filters import maximum_filter, median_filter\n",
    "import pandas as pd\n",
    "import madmom\n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from  collections import defaultdict as dd\n",
    "from time import time\n",
    "t0=time()\n",
    "#drums=drums[:nrOfDrums]\n",
    "\n",
    "#Tämä on vähän turha luokka, kaiken voi tallettaa drum objektiin\n",
    "class detector(object):\n",
    "    def __init__(self, drum,hitlist=None\n",
    "                 ,**kwargs):\n",
    "        # set attributes\n",
    "        self.drum = drum\n",
    "        if hitlist:\n",
    "            self.hitlist = hitlist   \n",
    "        else:\n",
    "            self.hitlist=None\n",
    "    def set_hits(self,hitlist):\n",
    "        self.hitlist=hitlist\n",
    "    def get_hits(self):\n",
    "        return self.hitlist\n",
    "    def get_name(self):\n",
    "        return self.drum.get_name()\n",
    "    def get_midinote(self):\n",
    "        return self.drum.get_midinote()\n",
    "    def get_threshold(self):\n",
    "        return self.drum.get_threshold()\n",
    "    def get_frequency_pre(self):\n",
    "        return self.drum.get_frequency_pre()\n",
    "    def get_probability_threshold(self):\n",
    "        return self.drum.get_probability_threshold()\n",
    "    \n",
    "peakList=[]\n",
    "for i in drums[:nrOfDrums]:\n",
    "    peakList.append(detector(i, hitlist=None))\n",
    "\n",
    "if 'cnn' not in globals():\n",
    "    from keras.models import load_model\n",
    "    cnn = load_model('./keras.model_testivedot.h5')\n",
    "    cnn.load_weights(\"./weights_testivedot.hdf5\")\n",
    "    \n",
    "#From https://stackoverflow.com/questions/1566936/\n",
    "class prettyfloat(float):\n",
    "    def __repr__(self):\n",
    "        return \"%0.3f\" % self\n",
    "\n",
    "#superlux from madmom (Böck et al)\n",
    "def superflux(A,B):\n",
    "    kernel=np.hamming(8)\n",
    "    from scipy.signal import convolve\n",
    "    B=convolve(B, kernel, 'same')\n",
    "    B=B/max(B)\n",
    "    spec_x=np.outer(A,B)\n",
    "    diff = np.zeros_like(spec_x.T)\n",
    "    size = (2,16)\n",
    "    max_spec = maximum_filter(spec_x.T, size=size)\n",
    "    diff[1:] = (spec_x.T[1:] - max_spec[: -1])\n",
    "    pos_diff = np.maximum(0, diff)\n",
    "    sf = np.sum(pos_diff, axis=1)\n",
    "    sf=sf/max(sf)\n",
    "    return sf\n",
    "\n",
    "def frame_to_time(frames, sr=44100, hop_length=HOP_SIZE, hops_per_frame=1):\n",
    "    samples= (np.asanyarray(frames) * (hop_length/hops_per_frame)).astype(int)\n",
    "    return np.asanyarray(samples) / float(sr)   \n",
    "def time_to_frame(times, sr=44100, hop_length=HOP_SIZE, hops_per_frame=1):\n",
    "    samples= (np.asanyarray(times) *float(sr))\n",
    "    return (np.asanyarray(samples)/ (hop_length/hops_per_frame)).astype(int)\n",
    "    \n",
    "\n",
    "def f_score(hits, hitNMiss, actual):\n",
    "        try:\n",
    "            precision=(float(hits)/hitNMiss)\n",
    "            recall=(float(hits)/actual)\n",
    "            fscore=(2*((precision*recall)/(precision+recall)))\n",
    "            return (precision, recall, fscore)\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            return (0.0,0.0,0.0)\n",
    "def k_in_n(k,n, window=1):\n",
    "    hits=0\n",
    "    for i in n:\n",
    "            for j in k:    \n",
    "                if (j-window <= i <= j+window): \n",
    "                    hits+=1\n",
    "                    break\n",
    "                if(j+window>i):\n",
    "                    break\n",
    "    return float(hits)\n",
    "\n",
    "MS_IN_MIN=60000\n",
    "SXTH_DIV=8\n",
    "#Create a mask of 16th notes for the duration of the drumtake based on the tempomap\n",
    "def tempoMask(tempos):\n",
    "    #Move all tempos to half-notes to counter erratic behaviour when tempo extraction doubles tempo value.\n",
    "    for i in range(tempos.size):\n",
    "        if tempos[i]>100:\n",
    "            while tempos[i]>100:\n",
    "                tempos[i]=tempos[i]/2\n",
    "    #define the length of a sixteenthnote in ms in relation to tempo at time t\n",
    "    sixtLength=MS_IN_MIN/tempos/SXTH_DIV\n",
    "    #define the length of a frame in ms\n",
    "    frameLength=1000*HOP_SIZE / SAMPLE_RATE\n",
    "    #extract indices in X that correspond to a 16th note in tempo at time t\n",
    "    #by calculating modulo and taking the inverse boolean array mod(a,b)==0 ==True\n",
    "    indices=np.array([int((s%(sixtLength[s]/frameLength))) for s in range(0,tempos.shape[0])])\n",
    "    invertedIndices=np.invert(indices.astype('bool'))\n",
    "    return invertedIndices\n",
    "\n",
    "#Quantize hits accordng to 16th Note mask\n",
    "def quantize(X, mask, strength=1, tempo=128, conform=False):\n",
    "    #Create a mask of constant tempo\n",
    "    if conform:\n",
    "        #drop less than 100 to half \n",
    "        if tempo<100:\n",
    "            tempo=tempo/2\n",
    "        conformMask=tempoMask(np.full(mask.size*2, tempo))\n",
    "        trueInd=np.where(mask==True)[0]\n",
    "        dim=min(np.where(conformMask==True)[0].size,trueInd.size )\n",
    "        cMask=np.where(conformMask==True)[0][:dim]-trueInd[:dim]\n",
    "        shiftMask=mask.astype(int)\n",
    "        n=0\n",
    "        for i in trueInd:\n",
    "            shiftMask[i]=cMask[n]\n",
    "            n+=1\n",
    "    #iterate found onsets\n",
    "    retX=np.zeros_like(X)\n",
    "    n=0\n",
    "    for i in X:\n",
    "        k=0\n",
    "        notfound=True\n",
    "        \n",
    "        #shift \n",
    "        j=0\n",
    "        \n",
    "        #set limit to shift\n",
    "        jLim=min(i, mask.size-i)\n",
    "        while notfound:\n",
    "            \n",
    "            #If the shift is at either end of the mask remove onset\n",
    "            if j==jLim:\n",
    "                notfound=False\n",
    "                k=None\n",
    "                \n",
    "            #If the onset is in 16th note mask\n",
    "            if mask[i]==True:\n",
    "                notfound=False\n",
    "                k=i\n",
    "                if conform:\n",
    "                    k+=shiftMask[i]\n",
    "                \n",
    "            #Move the onset forvard by j frames and compare,\n",
    "            #if 16th note found in the mask move the onset there\n",
    "            elif mask[i+j]==True:\n",
    "                notfound=False\n",
    "                k=i+j\n",
    "                if conform:\n",
    "                    k+=shiftMask[i+j]\n",
    "                \n",
    "            #backward move of the onset\n",
    "            elif mask[i-j]==True:\n",
    "                notfound=False\n",
    "                k=i-j\n",
    "                if conform:\n",
    "                    k+=shiftMask[i-j]\n",
    "                \n",
    "            #increase shift\n",
    "            j+=1\n",
    "        #Store the quantized value to return list    \n",
    "        retX[n]=int((k*strength+i*(1-strength)))\n",
    "        #increase return list index\n",
    "        n+=1\n",
    "\n",
    "    return retX[retX != np.array(None)]\n",
    "\n",
    "def get_cmask(tempo, tempomask):\n",
    "    \n",
    "    return cMask\n",
    "\n",
    "def semi_adaptive_NMFB(X,Wpre,n_iterations=100, alternate=False, adaptive=False, leeseung=False, div=1, sp=0):\n",
    "    if alternate==True:\n",
    "        n_iterations=n_iterations*2\n",
    "    [numRows,numCols] = X.shape\n",
    "    epsilon=10**-16\n",
    "    X = X + epsilon\n",
    "    W = Wpre\n",
    "    #H = np.ones((W.shape[1],numCols))\n",
    "    \n",
    "    H=abs(np.random.normal(0,0.5,[W.shape[1],numCols]))\n",
    "    err=np.zeros(n_iterations)\n",
    "    sparsity=sp\n",
    "    for i in range(W.shape[1]):\n",
    "        normB = np.linalg.norm(W[:,i], ord=np.inf)\n",
    "        W[:,i] = W[:,i]/normB\n",
    "    Wt = W.T\n",
    "    def KLDiv(x,y):\n",
    "        return sum(sum(x*np.log(x/y)+(y-x)))\n",
    "    def ISDiv(x,y):\n",
    "        return sum(sum((x/y)-np.log(x/y)-1))\n",
    "    def BRDiv(x,y):\n",
    "        return sum(sum((( 1 / (div * (div-1) )) * ( x**div + (div-1) * y**div -div * x * y**(div-1) ))))\n",
    "    def LS(x,y):\n",
    "        return sum(sum((x-y)**2))\n",
    "    WH = epsilon+np.dot(W,H)\n",
    "    for i in range(n_iterations):\n",
    "        \n",
    "        #Algorithm according to \"Battenberg et al. Live Drum Separation Using Probabilistic Spectral Clustering\"\n",
    "        if leeseung=='bat':\n",
    "            Himin=H\n",
    "            H = H*(Wt@(X*WH**(div-2)))/(epsilon+(Wt@WH**(div-1))+sparsity)\n",
    "            Ht = H.T\n",
    "        WH = epsilon+np.dot(W,H)    \n",
    "        normH = np.linalg.norm(H, ord=np.inf)\n",
    "        #IS-divergence\n",
    "        if div==0:\n",
    "            err[i]=ISDiv(X,WH)+(sparsity*normH)\n",
    "        #KL-divergence\n",
    "        elif div==1:\n",
    "            err[i]=KLDiv(X,WH)+(sparsity*normH)\n",
    "        #EUC-distance\n",
    "        elif div == 2:\n",
    "            err[i]=LS(X,WH)+(sparsity*normH)\n",
    "        # Bregman-divergence\n",
    "        else:\n",
    "            err[i]=BRDiv(X,WH)+(sparsity*normH)\n",
    "        sparsity=1/err[i]\n",
    "        if (i>=2) :              \n",
    "            if (abs(err[i] - err[i-1]) / (err[1] - err[i])+epsilon) < 0.001:\n",
    "                break    \n",
    "    Xpost=np.zeros((W.shape[1],numRows, numCols))\n",
    "    for i in range(int(W.shape[1])):\n",
    "        Xpost[i] = np.outer(W[:,i],H[i,:])\n",
    "    return Xpost, W, H\n",
    "\n",
    "\n",
    "##This removes the effect of reverb/echo. i.e. peak min resolution 20 frames\n",
    "def cleanDoubleStrokes(hitList, resolution=10):\n",
    "    if len(hitList)==0:\n",
    "        return hitList\n",
    "    hitList.sort()\n",
    "    retList=[]\n",
    "    lastSeenHit=-1*resolution\n",
    "    adjacents=[]\n",
    "    for i in hitList:\n",
    "        if len(adjacents)>=1:\n",
    "            if i>=np.min(adjacents)+resolution:\n",
    "                retList.append(np.min(adjacents))\n",
    "                lastSeenHit=np.min(adjacents)\n",
    "                adjacents=[]\n",
    "                \n",
    "        adjacents.append(i)\n",
    "    #add last hit to the list\n",
    "    retList.append(np.min(adjacents))\n",
    "    return (np.array(retList))\n",
    "\n",
    "\n",
    "\n",
    "#brickwall limiter to even out high peaks\n",
    "def limitToPercentile(data, limit=99.9, lowlimit=0, ratio=1):\n",
    "    limit=np.percentile(data,limit)\n",
    "    lowlimit=np.percentile(data,lowlimit)\n",
    "    highPeaks = abs(data) > limit # Where values higher than the percentile\n",
    "    data[highPeaks] = limit #brickwall the signal to the limit\n",
    "    lowPeaks = abs(data) < lowlimit # Where values higher than the percentile\n",
    "    data[lowPeaks] = 0 #brickwall the signal to the limit\n",
    "    return (data/max(data))\n",
    "def pruneCNN(foundhits, label, booster, thresh, buffer):\n",
    "        if booster==None:\n",
    "            return foundhits\n",
    "        v_X=[]\n",
    "        templates=[]\n",
    "        if foundhits.size==0:\n",
    "            return foundhits\n",
    "        for row in foundhits:\n",
    "            time=row\n",
    "            try:  \n",
    "                tinyBuff=make_sample(buffer, time, n_frames=4)                \n",
    "                v_X.append(generate_features(tinyBuff, peakList[label[0]].drum.get_highEmph()))\n",
    "            except:\n",
    "                \"\"\"muista panna paddia alkuun ja loppuun\"\"\" \n",
    "        from sklearn import preprocessing\n",
    "        scaler=preprocessing.MinMaxScaler()\n",
    "        v_X=scaler.fit_transform(np.array(v_X))\n",
    "        preds_CNN=booster.predict(v_X)\n",
    "        remove=[]\n",
    "        for i in range(len(preds_CNN)):\n",
    "            preds_CNN[i]=preds_CNN[i]/preds_CNN[i].max()\n",
    "            #topThree=preds_CNN[i].argsort()[-3:][::-1]\n",
    "            ##print (topThree)\n",
    "            #if label not in topThree:\n",
    "            #    if isSoundcheck<0:\n",
    "            #        remove.append(i)\n",
    "            #if np.argmin(preds_CNN[i])==label:\n",
    "            #    if isSoundcheck<0:\n",
    "            #        remove.append(i)\n",
    "            if (preds_CNN[i][label])<thresh:\n",
    "                remove.append(i)\n",
    "            ##OHH over CHH\n",
    "            #if label[0]==2 and preds_CNN[i][label]<=preds_CNN[i][3]:\n",
    "            #    if isSoundcheck<0:         \n",
    "            #        remove.append(i)\n",
    "            #CHH over OHH\n",
    "            #if label[0]==3 and preds_CNN[i][label]<=preds_CNN[i][2]:\n",
    "            #    if isSoundcheck<0:\n",
    "            #        remove.append(i)\n",
    "            ##OHH over Ride\n",
    "            #if label[0]==6 and preds_CNN[i][label]<=preds_CNN[i][3]:\n",
    "            #    if isSoundcheck<0:\n",
    "            #        remove.append(i)\n",
    "            ###CHH over HHStomp\n",
    "            #if label[0]==8 and  preds_CNN[i][label]<=preds_CNN[i][2]:\n",
    "            #    if isSoundcheck<0:\n",
    "            #        remove.append(i)    \n",
    "        return np.delete(foundhits, remove)\n",
    "#aloita ikkuna x[:-window]\n",
    "def movingAverage(x,window=500):\n",
    "        return median_filter(x, size=(window))\n",
    "from scipy.signal import argrelmax\n",
    "\n",
    "def pick_onsets(F, initialThreshold=0, delta=0):\n",
    "    # dynamic threshold from Bello et. al. sigma_hat[T]=initialThreshold+delta(median(window_at_T))\n",
    "    localMaximaInd=argrelmax(F) #max indices\n",
    "    localMaxima=F[localMaximaInd[0]]\n",
    "    Tdyn=initialThreshold+delta*(np.mean(localMaxima))\n",
    "    #T1, T2, Tdyn=np.zeros(F.shape[0]),np.zeros(F.shape[0]),np.zeros(F.shape[0])\n",
    "    #for i in range(F.shape[0]):\n",
    "    #    n=F[i:i+100]\n",
    "    #    \n",
    "    #    T1[i] = initialThreshold+delta*(np.percentile(n,75)-np.percentile(n, 25)) + np.percentile(n, 50)\n",
    "    #    T2[i] =0.1*np.percentile(n, 100)\n",
    "    #    p=2\n",
    "    #    Tdyn[i]=((T1[i]**p+T2[i]**p)/2.)**(1./p)\n",
    "    \n",
    "    onsets=np.array(localMaxima>=Tdyn)\n",
    "    return localMaximaInd[0][onsets]\n",
    "\n",
    "from scipy import signal\n",
    "def HFC_filter(X):\n",
    "    #b, a = signal.butter(4,0.5)\n",
    "    Xi=np.zeros(X.shape[1])\n",
    "    for i in range(X.shape[0]):\n",
    "        Xi+=i*100*X[i]\n",
    "    plt.figure()\n",
    "    plt.plot(Xi)\n",
    "    return (Xi/Xi.max())\n",
    "    \n",
    "def processLiveAudio(liveBuffer=None, booster=cnn, classifier='LGB', basis=None, quant_factor=0.0):\n",
    "\n",
    "    \n",
    "    filt_spec=get_preprocessed_spectrogram(liveBuffer)\n",
    "\n",
    "    Xpost, W, H = semi_adaptive_NMFB(filt_spec.T,basis,n_iterations=2000,\n",
    "                                     alternate=False, adaptive=False, leeseung='bat', div=0, sp=2)\n",
    "    if quant_factor>0:\n",
    "        bdTempo=(librosa.beat.tempo(onset_envelope=np.sum(H, axis=0), sr=SAMPLE_RATE,hop_length=HOP_SIZE,ac_size=8, aggregate=None))\n",
    "        bdAvg=movingAverage(bdTempo, window=1200)\n",
    "        #print(bdAvg.shape)    \n",
    "        #snTempo=(librosa.beat.tempo( onset_envelope=H[1], sr=SAMPLE_RATE,hop_length=HOP_SIZE))\n",
    "        #plt.figure()\n",
    "        ##plt.plot(movingAverage(snTempo, 0,bdTempo.shape))\n",
    "        #plt.plot(bdTempo, color='r')\n",
    "        #plt.plot(bdAvg, color='g')\n",
    "        #print(np.mean(bdTempo))\n",
    "        #print(np.mean(bdAvg))\n",
    "        #win=2000\n",
    "        #plt.plot(librosa.beat.tempo(onset_envelope=H[0], sr=SAMPLE_RATE,hop_length=HOP_SIZE\n",
    "        #                             , aggregate=movingAverage), color='b')\n",
    "        tempomask=tempoMask(bdAvg)\n",
    "\n",
    "    for i in peakList:\n",
    "        \n",
    "        H0=superflux(W[i.get_name()].T[0],H[i.get_name()][0])\n",
    "        \n",
    "        #HFCX0=HFC_filter(Xpost[i.get_name()][0])\n",
    "        #H0=superflux(W[i.get_name()].T[0],HFCX0)\n",
    "        peaks=pick_onsets(H0, initialThreshold=0.15, delta=1)\n",
    "        #peaks=madmom.features.onsets.peak_picking(H0 ,i.get_threshold(),\n",
    "        #                                       smooth=None, pre_avg=0, post_avg=0,pre_max=1, post_max=1)\n",
    "        if quant_factor>0:\n",
    "            TEMPO=120\n",
    "            qPeaks=quantize(peaks, tempomask, strength=quant_factor, tempo=TEMPO, conform=True)\n",
    "        else:\n",
    "            qPeaks=peaks\n",
    "        #cPeaks=conformToTempo(qPeaks, tempo, tempomask)\n",
    "        \n",
    "        #print((peaks, qPeaks))\n",
    "        peakList[i.get_name()[0]].set_hits(qPeaks)\n",
    "\n",
    "    duplicateResolution=0.03\n",
    "\n",
    "    for i in peakList:\n",
    "        precHits=frame_to_time(i.get_hits())\n",
    "        i.set_hits(time_to_frame(cleanDoubleStrokes(precHits, resolution=duplicateResolution)))\n",
    "   \n",
    "    #prune onsets with CNN classifier\n",
    "    if (classifier=='CNN'):\n",
    "\n",
    "        for i in peakList:\n",
    "            prob_thresh=i.get_probability_threshold()\n",
    "            i.set_hits(pruneCNN(i.get_hits(),i.get_name(), cnn,prob_thresh, liveBuffer))\n",
    "\n",
    "    \n",
    "    return peakList\n",
    "\n",
    "\n",
    "if 'cnn' not in globals():\n",
    "    from keras.models import load_model\n",
    "    cnn = load_model('./keras.model_testivedot.h5')\n",
    "souncheck=False\n",
    "if souncheck==True:\n",
    "    \n",
    "    print('reset all thresholds:')\n",
    "    for i in range(nrOfDrums):\n",
    "        drums[i].set_probability_threshold(0.01)\n",
    "        drums[i].set_threshold(0.)\n",
    "    print('done')\n",
    "    comp_buffer=np.zeros(0)\n",
    "    for i in range(nrOfDrums):\n",
    "        try:\n",
    "            buffer=(madmom.audio.Signal(\"{}drum{}.wav\".format(DRUMKIT_PATH,i),sample_rate=SAMPLE_RATE, frame_size=2048, hop_size=HOP_SIZE))\n",
    "            new_buffer=np.zeros(comp_buffer.shape[0]+buffer.shape[0])\n",
    "            new_buffer[:comp_buffer.shape[0]]=comp_buffer\n",
    "            new_buffer[comp_buffer.shape[0]:]=buffer\n",
    "            comp_buffer=new_buffer\n",
    "            \n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            print('jotain meni vikaan!')\n",
    "    drumtake_frame_count=buffer.shape[0]/HOP_SIZE\n",
    "    filt_spec=get_preprocessed_spectrogram(comp_buffer)\n",
    "    \n",
    "    Xpost, W, H = semi_adaptive_NMFB(filt_spec.T,fpr,n_iterations=2000, alternate=False, adaptive=False, leeseung='bat', div=0, sp=1.5)\n",
    "    \n",
    "    \n",
    "#############################ISTFT###########################\n",
    "    #from scipy.signal import istft\n",
    "    #print(Xpost[0].shape)\n",
    "    #for i in range(nrOfDrums):\n",
    "    #    wav=librosa.core.istft(filt_spec.T, hop_length=441, window='hann',\n",
    "    #      center=True, dtype=np.float32, length=None)\n",
    "    #    madmom.io.audio.write_wave_file(wav, './drum{}.wav'.format(i),sample_rate=SAMPLE_RATE)\n",
    "    \n",
    "    \n",
    "        \n",
    "    totalF, totalP, totalR=0,0,0\n",
    "    for i in range(nrOfDrums):\n",
    "        searchSpeed=0.05\n",
    "        found=0\n",
    "        n=np.array(0)\n",
    "        fscore,fscore_old=0.,0.\n",
    "        prec, prec_old=0.,0.\n",
    "        rec, rec_old=1.,1.\n",
    "        #kernel = np.kaiser(7,5)\n",
    "        H0=superflux(W.T[i],H[i])\n",
    "        #H0=H[i]/H[i].max()\n",
    "        #plt.figure()\n",
    "        #plt.plot(H0)\n",
    "        nreal=frame_to_time(drums[i].get_peaks()+i*drumtake_frame_count)\n",
    "        n_step=[]\n",
    "\n",
    "        #Change the while condition to prec, rec or fscore as needen\n",
    "        while (fscore_old<=fscore):\n",
    "        \n",
    "            n=madmom.features.onsets.peak_picking(H0,drums[i].get_threshold())\n",
    "            predHits=frame_to_time(n)\n",
    "            predHits=cleanDoubleStrokes(predHits, resolution=0.02)\n",
    "            drums[i].set_threshold(drums[i].get_threshold()+searchSpeed)\n",
    "            if(drums[i].get_threshold()>1):\n",
    "                drums[i].set_threshold(1)\n",
    "                break\n",
    "            if (n.size==0):\n",
    "                continue\n",
    "                \n",
    "            #Count actual hits\n",
    "           \n",
    "            \n",
    "            hit=k_in_n(nreal,predHits,window=0.05)\n",
    "            #store old values\n",
    "            fscore_old, prec_old, rec_old=fscore, prec, rec\n",
    "            \n",
    "            #fscore\n",
    "            #print(fscore)\n",
    "            prec, rec, fscore=f_score(hit, n.shape[0], drums[i].get_peaks().shape[0])\n",
    "            \n",
    "           \n",
    "            n_step=n\n",
    "        \n",
    "            \n",
    "        drums[i].set_threshold(drums[i].get_threshold()-searchSpeed)\n",
    "        print(drums[i].get_threshold())\n",
    "        #\n",
    "        ##totalP+=prec_old\n",
    "        ##totalR+=rec_old\n",
    "        ##totalF+=fscore_old\n",
    "        if(False):\n",
    "            \n",
    "            fscore_old=0.\n",
    "            searchSpeed=0.01\n",
    "            while(fscore_old<=fscore):\n",
    "                \n",
    "                prob_thresh=drums[i].get_probability_threshold()\n",
    "                drums[i].set_probability_threshold(drums[i].get_probability_threshold()+searchSpeed)\n",
    "                n=pruneCNN(n_step,drums[i].get_name(), cnn,prob_thresh, comp_buffer)\n",
    "                predHits=frame_to_time(n)\n",
    "                \n",
    "                if(drums[i].get_probability_threshold()>1):\n",
    "                    drums[i].set_probability_threshold(1)\n",
    "                    break            \n",
    "                if (n.size==0):\n",
    "                    continue\n",
    "                #Count actual hits\n",
    "                hit=k_in_n(nreal,predHits,window=0.02)\n",
    "                #store old values\n",
    "                fscore_old, prec_old, rec_old=fscore, prec, rec\n",
    "                prec, rec, fscore=f_score(hit, n.shape[0], drums[i].get_peaks().shape[0])\n",
    "                \n",
    "            drums[i].set_probability_threshold(drums[i].get_probability_threshold()-searchSpeed)\n",
    "            print(drums[i].get_probability_threshold())\n",
    "            print()\n",
    "        totalP+=prec_old\n",
    "        totalR+=rec_old\n",
    "        totalF+=fscore_old\n",
    "        \n",
    "        \n",
    "        \n",
    "    print('Precision: {}'.format(totalP/(nrOfDrums*1)))\n",
    "    print('Recall: {}'.format(totalR/(nrOfDrums*1)))\n",
    "    print('F-score: {}'.format(totalF/(nrOfDrums*1)))\n",
    "    \n",
    "live=False\n",
    "if (live):    \n",
    "    #live audio\n",
    "    print(\"KOMPPIA!!\")\n",
    "    buffer=np.zeros(shape=(1024000*2))\n",
    "    j=0\n",
    "    strm=madmom.audio.signal.Stream(sample_rate=44100, num_channels=1,frame_size=2048, hop_size=HOP_SIZE)\n",
    "    for i in strm:\n",
    "            #print(i.shape)\n",
    "            buffer[j:j+HOP_SIZE]=i[:HOP_SIZE]\n",
    "            j+=HOP_SIZE\n",
    "            if j>=221792*recordingLength:\n",
    "                buffer[j:j+6000]=np.zeros(6000)\n",
    "                plst=processLiveAudio(liveBuffer=buffer ,booster=cnn, classifier='CNN')\n",
    "                for drum in plst:\n",
    "                    add_to_samples_and_dictionary(drum, buffer, drum.get_hits())\n",
    "                strm.close()\n",
    "                break\n",
    "                buffer=np.zeros(shape=(1024000*2))\n",
    "                j=0\n",
    "else: \n",
    "    try:\n",
    "\n",
    "        buffer=madmom.audio.Signal(\"{}drumBeatAnnod.wav\".format(DRUMKIT_PATH),frame_size=2048, hop_size=HOP_SIZE)\n",
    "        \n",
    "    \n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        print('jotain meni vikaan!')\n",
    "    plst=processLiveAudio(liveBuffer=buffer ,booster=cnn, classifier='None', basis=fpr, quant_factor=0.0)\n",
    "    \n",
    "    #print f-score:\n",
    "    import pandas as pd\n",
    "    hits = pd.read_csv(\"{}midiBeatAnnod.csv\".format(DRUMKIT_PATH), sep=\"\\t\", header=None)\n",
    "    precision, recall, fscore, true_tot=0,0,0,0\n",
    "    for i in plst:\n",
    "        predHits=frame_to_time(i.get_hits())\n",
    "        \n",
    "        #print(predHits, predHits.shape[0] )\n",
    "        actHits=hits[hits[1]==i.get_name()[0]]\n",
    "        actHits = actHits.iloc[:,0] \n",
    "        #print(actHits.values, actHits.shape[0])\n",
    "        trueHits=k_in_n(actHits.values,predHits, window=0.02)\n",
    "        #print(trueHits)\n",
    "        \n",
    "        prec, rec, f_drum=f_score(trueHits, predHits.shape[0], actHits.shape[0])\n",
    "        print(prec)\n",
    "        print(rec)\n",
    "        print(f_drum)\n",
    "        print(trueHits)\n",
    "        print('\\n')\n",
    "        #Multiply by n. of hits to get real f-score in the end.\n",
    "        precision+=prec*actHits.shape[0]\n",
    "        recall+=rec*actHits.shape[0]\n",
    "        fscore+=(f_drum*actHits.shape[0])\n",
    "        true_tot+=actHits.shape[0]\n",
    "        #add_to_samples_and_dictionary(i.drum, buffer, i.get_hits())\n",
    "    print('Precision: {}'.format(precision/true_tot))\n",
    "    print('Recall: {}'.format(recall/true_tot))\n",
    "    print('F-score: {}'.format(fscore/true_tot))\n",
    "            \n",
    "'''\n",
    "todo: Normalize freq -bands locally to adjust to signal level changing during performance\n",
    "    frame by frame or something else, a window of fixeld length maybe?\n",
    "    \n",
    "'''\n",
    "\n",
    "\n",
    "import madmom\n",
    "import numpy as np\n",
    "\n",
    "times=[]\n",
    "for i in plst:\n",
    "    hits=frame_to_time(i.get_hits())\n",
    "    labels=np.full(len(hits),i.get_midinote(),np.int64)\n",
    "    inst=zip(hits,labels)\n",
    "    times.extend(inst)\n",
    "times.sort()\n",
    "df=pd.DataFrame(times, columns=['time','inst'])\n",
    "df['duration']=pd.Series(np.full((len(times)),1,np.int64))\n",
    "df['vel']=pd.Series(np.full((len(times)),127,np.int64))\n",
    "df = df[df.time != 0]\n",
    "print('done!')\n",
    "madmom.io.midi.write_midi(df.values,'midi_testit.mid')\n",
    "df.to_csv('testbeat.csv', index=False, header=False,sep=\"\\t\" )\n",
    "print ('Processing time:%0.2f' %(time()-t0))\n",
    "\n",
    "#Thresholdit checkissä.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyOnset: fixed thresh 0.1\n",
    "Precision: 0.5874198982747415\n",
    "Recall: 0.8896210873146623\n",
    "F-score: 0.6752813659346235\n",
    "dyn thresh mean over onsets:\n",
    "Precision: 0.6835106931254392\n",
    "Recall: 0.8105436573311368\n",
    "F-score: 0.7214062464341031\n",
    "with calc initThresh:\n",
    "Precision: 0.8258341125493192\n",
    "Recall: 0.45634266886326197\n",
    "F-score: 0.5298143559461154\n",
    "    \n",
    "Dyn thresh Battenberg:\n",
    "Precision: 0.7760259086390112\n",
    "Recall: 0.6457990115321252\n",
    "F-score: 0.6683809592682705\n",
    "\n",
    "Precision: 0.7179977613744256\n",
    "Recall: 0.5321252059308073\n",
    "F-score: 0.5745499549092695\n",
    "Precision: 0.8470295568774687\n",
    "Recall: 0.6062602965403624\n",
    "F-score: 0.6548100276742633\n",
    "Precision: 0.8355450047507559\n",
    "Recall: 0.6029654036243822\n",
    "F-score: 0.659857056467321\n",
    "    \n",
    "'''  \n",
    "Precision: 0.7744728798280499\n",
    "Recall: 0.6803953871499177\n",
    "F-score: 0.7164358088958612\n",
    "    \n",
    "Precision: 0.7910477522507651\n",
    "Recall: 0.6375617792421746\n",
    "F-score: 0.673058993914712\n",
    "    \n",
    "Precision: 0.7599937894820988\n",
    "Recall: 0.6309719934102141\n",
    "F-score: 0.6771666148571838\n",
    "    Precision: 0.6068932552975671\n",
    "Recall: 0.5201960443704864\n",
    "F-score: 0.5415296815491364None\n",
    "    \n",
    "0    0.49312751926196907\n",
    "0.1   0.5959200249552901\n",
    "0.5    0.6632823192395939\n",
    "0.75   0.6494098328089922\n",
    "1    0.6490349973355233 3frameprior 0.7758019899131032 5frame hanning 0.8034906359904352\n",
    "2    0.570457331174177\n",
    "\n",
    "1 best sp=-0.5 dupthresh=6\n",
    "\n",
    "Precision: 0.814842445516188\n",
    "Recall: 0.8645833333333334\n",
    "F-score: 0.8175727163599952\n",
    "    \n",
    "    Precision: 0.8624453854943873\n",
    "Recall: 0.6701388888888888\n",
    "F-score: 0.7218231992806143\n",
    "    Precision: 0.8517537359732343\n",
    "Recall: 0.84375\n",
    "F-score: 0.8024892252459598\n",
    "    \n",
    "    \n",
    "Results for 4 drums, kick, sn, chh, ohh\n",
    "Precision: 0.9660138248847927\n",
    "Recall: 0.9296875\n",
    "F-score: 0.9468253968253968\n",
    "    \n",
    "Results for 8 drums, set - stomp\n",
    "Precision: 0.909137651476361\n",
    "Recall: 0.828125\n",
    "F-score: 0.8645396270755279\n",
    "    \n",
    "Results for all drums:\n",
    "Precision: 0.8528470064875037\n",
    "Recall: 0.8298611111111112\n",
    "F-score: 0.824505931901196\n",
    "    \n",
    "Results for IS:\n",
    "Precision: 0.8903312254832697\n",
    "Recall: 0.8680555555555556\n",
    "F-score: 0.8586254265016885\n",
    "    double\n",
    "Precision: 0.9282671397366737\n",
    "Recall: 0.9097222222222222\n",
    "F-score: 0.915646993676403\n",
    "    \n",
    "Results for 0.5:\n",
    "Precision: 0.875369968758936\n",
    "Recall: 0.8819444444444444\n",
    "F-score: 0.8634949080893939\n",
    "\n",
    "results for KL:\n",
    "Precision: 0.8815530630741977\n",
    "Recall: 0.8229166666666666\n",
    "F-score: 0.8143141620982823\n",
    "    \n",
    "results for EUC:\n",
    "Precision: 0.8362107756322937\n",
    "Recall: 0.7534722222222222\n",
    "F-score: 0.783267689723791\n",
    "for i in range(nrOfDrums):\n",
    "    print(plst[i].drum.get_threshold())\n",
    "    plst[i].drum.set_threshold(0.4)\n",
    "    plst[i].drum.set_probability_threshold(.5)\n",
    "    '''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midinotes=[36,38,42,46,50,45,51,49,40] #BD, SN, CHH, OHH, TT, FT, RD, CR, SHH\n",
    "markup=pd.read_csv('./trainSamplet/midiBeatAnnod_orig.csv', names=['inst', 'time'], sep=\"\\t\", usecols=[2,5])\n",
    "print(markup.head(20))\n",
    "latencyCompensation=20\n",
    "                     #+markup['time'].iloc[0]-markup['time'].iloc[1])\n",
    "print(latencyCompensation)\n",
    "markup=markup.iloc[:]\n",
    "bdmask = (markup['inst'] ==36) | (markup['inst'] ==86)\n",
    "snmask = (markup['inst'] ==38) | (markup['inst'] ==40) | (markup['inst'] ==87)| (markup['inst'] ==85)\n",
    "chhmask = (markup['inst'] ==79) | (markup['inst'] ==46) | (markup['inst'] ==42)\n",
    "ohhmask = (markup['inst'] ==78)\n",
    "shhmask=  (markup['inst'] ==44)\n",
    "ttmask = (markup['inst'] ==48) | (markup['inst'] ==14)\n",
    "ft1mask = (markup['inst'] ==47) | (markup['inst'] ==18)\n",
    "ridemask = (markup['inst'] ==51) | (markup['inst'] ==52) | (markup['inst'] ==53)\n",
    "crmask = (markup['inst'] ==16) | (markup['inst'] ==17)  | (markup['inst'] ==57)|(markup['inst'] ==55) | (markup['inst'] ==59)  | (markup['inst'] ==49)\n",
    "crapmask = (markup['inst'] ==23) | (markup['inst'] ==19) | (markup['inst'] ==37) \n",
    "markup=markup.set_value(bdmask, 'inst', 0) \n",
    "markup=markup.set_value(snmask, 'inst', 1)\n",
    "markup=markup.set_value(chhmask, 'inst', 2)\n",
    "markup=markup.set_value(ohhmask, 'inst', 3)\n",
    "markup=markup.set_value(ttmask, 'inst', 4) \n",
    "markup=markup.set_value(ft1mask, 'inst', 5)\n",
    "markup=markup.set_value(ridemask, 'inst', 6) \n",
    "markup=markup.set_value(crmask, 'inst', 7)\n",
    "markup=markup.set_value(shhmask, 'inst', 8)\n",
    "markup=markup.set_value(crapmask, 'inst', 9)\n",
    "#markup=markup.set_value(bdsnchhmask, 'inst', 8)\n",
    "#jne.\n",
    "markup['time'] = markup['time'].apply(lambda x: (x+latencyCompensation)/1000.0)\n",
    "markup=markup[['time', 'inst']]\n",
    "print(markup.head(20))\n",
    "markup.to_csv('./trainSamplet/midiBeatAnnod.csv', index=False, header=False,sep=\"\\t\")\n",
    "print(1111-249)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from keras.optimizers import sgd as SGD\n",
    "#from keras.layers.advanced_activations import ELU\n",
    "#from keras.utils import np_utils\n",
    "from keras.layers import Convolution2D, Convolution1D, GRU, LSTM,BatchNormalization\n",
    "#from keras.layers import MaxPooling2D, MaxPooling1D, AveragePooling2D\n",
    "#from keras.layers import Flatten, Input\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "#import librosa as lb\n",
    "#from os import listdir\n",
    "#import lightgbm as lgb\n",
    "#import pickle\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "\n",
    "\n",
    "#Tähän vähän oppimista yms.!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def semi_adaptive_NMF(X,Wpre,n_iterations=100):\n",
    "    [numRows,numCols] = X.shape\n",
    "    #No more div by zero\n",
    "    epsilon=np.nextafter(0,1)\n",
    "    X = X + epsilon\n",
    "    W = Wpre\n",
    "    H = np.ones((nrOfDrums,numCols))\n",
    "    weight = np.linspace(0,1,n_iterations)\n",
    "    beta=2\n",
    "    adaptDegree=1*np.ones((1,nrOfDrums))\n",
    "    adaptPower=4*np.ones((1,nrOfDrums))\n",
    "    for i in range(n_iterations):\n",
    "        WH = epsilon+np.dot(W,H);\n",
    "        Wt = W.T;\n",
    "        H = H*(np.dot(Wt,(X*WH**(beta-2))))/( epsilon+np.dot(Wt,(WH**(beta-1))));\n",
    "        Ht = H.T;\n",
    "        WH = epsilon+np.dot(W,H)\n",
    "        W = W*(np.dot((X*WH**(beta-2)),Ht))/(epsilon+(np.dot((WH**(beta-1)),Ht)));  \n",
    "        blending_parameter = np.matlib.repmat((weight[i]*adaptDegree)**adaptPower,numRows,1)\n",
    "        blending_parameter[:,adaptDegree[0] > 1.0] = 1\n",
    "        initWeight = 1-blending_parameter\n",
    "        W = W*blending_parameter + Wpre*initWeight\n",
    "        normB = 1/(epsilon+sum(W))\n",
    "        W = W*normB\n",
    "    Xpost=np.zeros((nrOfDrums,24, numCols))\n",
    "    for i in range(nrOfDrums):\n",
    "        Xpost[i] = np.outer(W[:,i],H[i,:])\n",
    "    return Xpost, W, H\n",
    "def semi_adaptive_NMF2(X,Wpre,n_iterations=100, alternate=True):\n",
    "    if alternate==True:\n",
    "        n_iterations=n_iterations*2\n",
    "    [numRows,numCols] = X.shape\n",
    "    epsilon=0.000000001\n",
    "    X = X + epsilon\n",
    "    W = Wpre\n",
    "    H = np.ones((Wpre.shape[1],numCols))\n",
    "    weight = np.linspace(0,1,n_iterations)\n",
    "    beta=4\n",
    "    adaptDegree=1*np.ones((1,Wpre.shape[1]))\n",
    "    adaptPower=4*np.ones((1,Wpre.shape[1]))\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        WH = epsilon+np.dot(W,H);\n",
    "        onemat=np.ones_like(WH)\n",
    "        Wt = W.T;\n",
    "        #If alternating, update H every second turn, every second keep constanst.\n",
    "        if (alternate==True) and (i%2==0):\n",
    "            H = H*(np.dot(Wt,(WH**float(-2))*X))/( epsilon+np.dot(Wt,(WH)))\n",
    "        else:\n",
    "            H = H*(np.dot(Wt,(X/WH)))/( epsilon+np.dot(Wt,onemat))\n",
    "        Ht = H.T;\n",
    "        #Update WH if not alternating\n",
    "        if alternate==False:\n",
    "            WH = epsilon+np.dot(W,H)\n",
    "        #If alternating, update W every second turn, every second keep constanst.\n",
    "        if (alternate==True) and (i%2==1):\n",
    "            W = W*(np.dot((WH**float(-2))*X,Ht))/(epsilon+(np.dot((WH**float(-1)),Ht)))\n",
    "        else:\n",
    "            W = W*(np.dot((X/WH),Ht))/(epsilon+(np.dot(onemat,Ht)))\n",
    "        alpha=(1-(i/n_iterations))**beta\n",
    "        W=alpha*Wpre+(1-alpha)*W\n",
    "        normB = 1/(epsilon+sum(W))\n",
    "        W = W*normB\n",
    "        \n",
    "    Xpost=np.zeros((nrOfDrums,24, numCols))\n",
    "    for i in range(nrOfDrums):\n",
    "        Xpost[i] = np.outer(W[:,i],H[i,:])\n",
    "    return Xpost, W, H\n",
    "\n",
    "\n",
    "#DRUM TRANSCRIPTION USING PARTIALLY FIXED NON-NEGATIVE MATRIX FACTORIZATION WITH TEMPLATE ADAPTATION\n",
    "#Chih-Wei Wu, Alexander Lerch\n",
    "def semi_adaptive_NMF3(X,Wpre,n_iterations=100, alternate=False, adaptive=True, leeseung=False, div=1):\n",
    "    if alternate==True:\n",
    "        n_iterations=n_iterations*2\n",
    "    [numRows,numCols] = X.shape\n",
    "    epsilon=10**-9\n",
    "    X = X + epsilon\n",
    "    Wd = Wpre\n",
    "    Hd = np.ones((Wd.shape[1],numCols))\n",
    "    Wh = np.ones_like(Wd)\n",
    "    Hh = np.ones((Wd.shape[1],numCols))\n",
    "    weight = np.linspace(0,1,n_iterations)\n",
    "    beta=4\n",
    "    onemat=np.ones((numRows,numCols))\n",
    "    nrOfHarmonics=0\n",
    "    alpha=(Wd.shape[1]+nrOfHarmonics)/Wd.shape[1]\n",
    "    div_anneal=div\n",
    "    err=np.zeros(n_iterations)\n",
    "    def KLDiv(x,y):\n",
    "        return sum(sum(x*np.log(x/y)+(y-x)))\n",
    "    def ISDiv(x,y):\n",
    "        return sum(sum((x/y)-np.log(x/y)-1))\n",
    "    for i in range(n_iterations):\n",
    "        #if i<(n_iterations/2):\n",
    "        #    div_anneal=2\n",
    "        #elif i==(n_iterations/2):\n",
    "        #    div_anneal=1\n",
    "        #elif i>(n_iterations/2):\n",
    "        #    div_anneal=0\n",
    "        #div_anneal-=div/n_iterations\n",
    "        normB = 1/(epsilon+sum(Wd))\n",
    "        Wd = Wd*normB\n",
    "        normB = 1/(epsilon+sum(Wh))\n",
    "        Wh = Wh*normB\n",
    "        def updateJ():\n",
    "            WHd = alpha*(epsilon+np.dot(Wd,Hd));\n",
    "            WHh = (alpha**(-1))*(epsilon+np.dot(Wh,Hh));\n",
    "            J=X/(WHd+peta)\n",
    "            return WHd,WHh,J \n",
    "        WHd, WHh, J =updateJ()\n",
    "        Wdt = Wd.T\n",
    "        Wht = Wh.T\n",
    "        #Algorithm according to \"Battenberg et al. Live Drum Separation Using Probabilistic Spectral Clustering\"\n",
    "        if leeseung=='bat':\n",
    "            Hd = Hd*(Wdt@(J*WHd**(div_anneal-2)))/(epsilon+(Wdt@WHd**(div_anneal-1)))\n",
    "            Hdt = Hd.T\n",
    "            #Wd = Wd*((WHd**(div_anneal-2)*J)@Hdt)/(epsilon+(WHd**(div_anneal-1)@Hdt))\n",
    "        if leeseung==False:\n",
    "            if alternate==False:\n",
    "                Hd = Hd*(Wdt@(J*WHd**(div-2)))/(epsilon+(Wdt@WHd**(div-1)))\n",
    "                Hdt = Hd.T\n",
    "                Hh = Hh*(Wht@(J*WHh**(div-2)))/(epsilon+(Wht@WHh))  \n",
    "                Hht = Hh.T\n",
    "                Wh = Wh*((WHh**(div-2)*J)@Hht)/(epsilon+(WHh**(div-1)@Hht))\n",
    "                Wdh, WHh, J =updateJ()\n",
    "                if (adaptive==True):\n",
    "                    Wd = Wd*((WHd**(div-2)*J)@Hdt)/(epsilon+(WHd**(div-1)@Hdt))\n",
    "            if alternate==True:\n",
    "                if (i%2==0):\n",
    "                    Hd = Hd*(Wdt@(J*WHd**(div-2)))/(epsilon+(Wdt@WHd**(div-1)))\n",
    "                Hdt = Hd.T\n",
    "                if(i%2==0):       \n",
    "                    Hh = Hh*(Wht@(J*WHh**(div-2)))/(epsilon+(Wht@WHh))  \n",
    "                Hht = Hh.T\n",
    "                if(i%2==0):\n",
    "                    Wh = Wh*((WHh**(div-2)*J)@Hht)/(epsilon+(WHh**(div-1)@Hht))\n",
    "                Wdh, WHh, J =updateJ()\n",
    "                if(i%2==1):\n",
    "                    if (adaptive==True):\n",
    "                        Wd = Wd*((WHd**(div-2)*J)@Hdt)/(epsilon+(WHd**(div-1)@Hdt))\n",
    "                    \n",
    "        ###Algorithm according to \"LEE&SEUNG: Algorithms for non-negative matrix factorization\"\n",
    "        if leeseung==True:\n",
    "            if (alternate==True) and (i%2==0):\n",
    "                Hd = Hd*(np.dot(Wdt,J))/(epsilon+np.dot(Wdt,onemat))\n",
    "            Hdt = Hd.T\n",
    "            if (alternate==True) and (i%2==0):\n",
    "                Hh = Hh*(np.dot(Wht,J))/( epsilon+np.dot(Wht,onemat))\n",
    "            Hht = Hh.T\n",
    "            if (alternate==True) and (i%2==0):\n",
    "                Wh = Wh*(np.dot(J,Hht))/(epsilon+(np.dot(onemat,Hht)))\n",
    "            Wdh, WHh, J =updateJ()\n",
    "            if (alternate==True) and (i%2==1):\n",
    "                if adaptive==True:\n",
    "                    Wd = Wd*(np.dot(J,Hdt))/(epsilon+(np.dot(onemat,Hdt)))\n",
    "\n",
    "        #Semi adaptive Wd\n",
    "        if adaptive=='Semi'and (i%2==1):\n",
    "            gamma=(1-(i/n_iterations))**div_anneal\n",
    "            Wd=gamma*Wpre[:,Wd.shape[1]]+(1-gamma)*Wd\n",
    "        if div<=0:\n",
    "            err[i]=ISDiv(X,Wd@Hd)\n",
    "        elif div==1:\n",
    "            err[i]=KLDiv(X,Wd@Hd)\n",
    "        else :\n",
    "            err[i]=KLDiv(X,Wd@Hd)\n",
    "        if (i>=2) :              \n",
    "            if (abs(err[i] - err[i-1]) / (err[1] - err[i])+epsilon) < 0.0001:\n",
    "                break\n",
    "        \n",
    "    Xpost=np.zeros((Wd.shape[1],numRows, numCols))\n",
    "    for i in range(int(Wd.shape[1])):\n",
    "        Xpost[i] = np.outer(Wd[:,i],Hd[i,:])\n",
    "    return Xpost, Wd, Hd\n",
    "def semi_adaptive_NMF4(X,Wpre,n_iterations=100, alternate=False, adaptive=True, leeseung=False, div=1.5):\n",
    "    if alternate==True:\n",
    "        n_iterations=n_iterations*2\n",
    "    [numRows,numCols] = X.shape\n",
    "    epsilon=10**-16\n",
    "    X = X + epsilon\n",
    "    W = Wpre\n",
    "    Wt = W.T\n",
    "    H = np.ones((W.shape[1],numCols))\n",
    "    err=np.zeros(n_iterations)\n",
    "    sparsity=0\n",
    "    for i in range(W.shape[1]):\n",
    "        normB = np.linalg.norm(W[:,i], ord=np.inf)\n",
    "        W[:,i] = W[:,i]/normB\n",
    "    def KLDiv(x,y):\n",
    "        return sum(sum(x*np.log(x/y)+(y-x)))\n",
    "    def ISDiv(x,y):\n",
    "        return sum(sum((x/y)-np.log(x/y)-1))\n",
    "    def BRDiv(x,y):\n",
    "        return sum(sum(((1/(div*(div-1)))*(x**div+(div-1)*y**div-div*x*y**(div-1)))))\n",
    "    for i in range(n_iterations):\n",
    "        WH = epsilon+np.dot(W,H)\n",
    "        #Algorithm according to \"Battenberg et al. Live Drum Separation Using Probabilistic Spectral Clustering\"\n",
    "        if leeseung=='bat':\n",
    "            H = H*(Wt@(X*WH**(div-2)))/(epsilon+(Wt@WH**(div-1))+sparsity)\n",
    "            Ht = H.T\n",
    "        \n",
    "        #Semi adaptive Wd\n",
    "        if adaptive=='Semi'and (i%2==1):\n",
    "            gamma=(1-(i/n_iterations))**div\n",
    "            W=gamma*Wpre[:,W.shape[1]]+(1-gamma)*W\n",
    "       \n",
    "    \n",
    "        normH = np.linalg.norm(H, ord=np.inf)\n",
    "        #IS-divergence\n",
    "        if div==0:\n",
    "            err[i]=ISDiv(X,W@H)+(sparsity*normH)\n",
    "        #KL-divergence\n",
    "        elif div==1:\n",
    "            err[i]=KLDiv(X,W@H)+(sparsity*normH)\n",
    "        # Bregman-divergence\n",
    "        else:\n",
    "            err[i]=BRDiv(X,W@H)+(sparsity*normH)\n",
    "        if (i>=2) :              \n",
    "            if (abs(err[i] - err[i-1]) / (err[1] - err[i])+epsilon) < 0.0001:\n",
    "                break    \n",
    "    Xpost=np.zeros((W.shape[1],numRows, numCols))\n",
    "    \n",
    "    for i in range(int(W.shape[1])):\n",
    "        Xpost[i] = np.outer(W[:,i],H[i,:])\n",
    "    return Xpost, W, H\n",
    "def semi_adaptive_NMFB(X,Wpre,n_iterations=100, alternate=False, adaptive=False, leeseung=False, div=1, sp=0):\n",
    "    if alternate==True:\n",
    "        n_iterations=n_iterations*2\n",
    "    [numRows,numCols] = X.shape\n",
    "    epsilon=10**-16\n",
    "    X = X + epsilon\n",
    "    W = Wpre\n",
    "    H = np.ones((W.shape[1],numCols))\n",
    "    err=np.zeros(n_iterations)\n",
    "    sparsity=sp\n",
    "    for i in range(W.shape[1]):\n",
    "        normB = np.linalg.norm(W[:,i], ord=np.inf)\n",
    "        W[:,i] = W[:,i]/normB\n",
    "    Wt = W.T\n",
    "    def KLDiv(x,y):\n",
    "        return sum(sum(x*np.log(x/y)+(y-x)))\n",
    "    def ISDiv(x,y):\n",
    "        return sum(sum((x/y)-np.log(x/y)-1))\n",
    "    def BRDiv(x,y):\n",
    "        return sum(sum((( 1 / (div * (div-1) )) * ( x**div + (div-1) * y**div -div * x * y**(div-1) ))))\n",
    "    def LS(x,y):\n",
    "        return sum(sum((x-y)**2))\n",
    "    WH = epsilon+np.dot(W,H)\n",
    "    for i in range(n_iterations):\n",
    "        \n",
    "        #Algorithm according to \"Battenberg et al. Live Drum Separation Using Probabilistic Spectral Clustering\"\n",
    "        if leeseung=='bat':\n",
    "            Himin=H\n",
    "            H = H*(Wt@(X*WH**(div-2)))/(epsilon+(Wt@WH**(div-1))+sparsity)\n",
    "            Ht = H.T\n",
    "        WH = epsilon+np.dot(W,H)    \n",
    "        normH = np.linalg.norm(H, ord=np.inf)\n",
    "\n",
    "        if div==0:\n",
    "            err[i]=ISDiv(X,WH)+(sparsity*normH)\n",
    "            #print('Error: {}'.format(err[i]))\n",
    "        #KL-divergence\n",
    "        elif div==1:\n",
    "            err[i]=KLDiv(X,WH)+(sparsity*normH)\n",
    "            #print('Error: {}'.format(err[i]))\n",
    "        elif div == 2:\n",
    "            err[i]=LS(X,WH)+(sparsity*normH)\n",
    "            #print('Error: {}'.format(err[i]))\n",
    "        # Bregman-divergence\n",
    "        else:\n",
    "            err[i]=BRDiv(X,WH)+(sparsity*normH)\n",
    "            #print('Error: {}'.format(err[i]))\n",
    "        sparsity=1/err[i]\n",
    "        if (i>=2) :              \n",
    "            if (abs(err[i] - err[i-1]) / (err[1] - err[i])+epsilon) < 0.005:\n",
    "                #print('Iterations: {}'.format(i))\n",
    "                #print('Error: {}'.format(err[i]))\n",
    "                break    \n",
    "    Xpost=np.zeros((W.shape[1],numRows, numCols))\n",
    "    for i in range(int(W.shape[1])):\n",
    "        Xpost[i] = np.outer(W[:,i],H[i,:])\n",
    "    return Xpost, W, H\n",
    "#try:\n",
    "#\n",
    "#    buffer=madmom.audio.Signal(\"./oikeetsamplet/drumBeat.wav\",frame_size=2048, hop_size=HOP_SIZE)\n",
    "#    \n",
    "#except Exception as e:\n",
    "#    print (e)\n",
    "#    print('jotain meni vikaan!')\n",
    "##proc=madmom.audio.filters.BarkFilterbank(np.array(range(0,16384, 16)))\n",
    "##filt_spec = madmom.audio.spectrogram.FilteredSpectrogram(buffer, filterbank=proc, sample_rate=44100, fmin=20)\n",
    "filt_spec=get_preprocessed_spectrogram(comp_buffer)\n",
    "#filt_spec=muLaw(filt_spec, mu=10**8)\n",
    "#filt_spec=(filt_spec+50)\n",
    "#filt_spec=np.sqrt(filt_spec)\n",
    "#filt_spec=madmom.audio.Spectrogram(buffer)\n",
    "#filt_spec=muLaw(filt_spec, mu=0.0001)\n",
    "#for i in range (nrOfDrums):\n",
    "#\n",
    "#    plt.figure()\n",
    "#    plt.plot(fpr.T[i])\n",
    "#    plt.ylim(0,24)\n",
    "#    plt.figure()\n",
    "#    plt.plot(fpr.T[i+nrOfDrums])\n",
    "#    plt.ylim(0,24)\n",
    "\n",
    "Xpost, W, H = semi_adaptive_NMFB(filt_spec.T,fpr,\n",
    "                                 n_iterations=20000, alternate=False,\n",
    "                                 adaptive=False, leeseung='bat', div=0)\n",
    "\n",
    "Hmu=np.zeros_like(H)\n",
    "Wp=np.linalg.pinv(W)\n",
    "#for i in range (nrOfDrums):\n",
    "    #Xpost[i]=muLaw(Xpost[i].T, mu=0.5).T\n",
    "    #Hmu[i]=(Wp[i]@Xpost[i])\n",
    "#from librosa.core import istft\n",
    "def smoothed_subband_mean(Y):\n",
    "    kernel = np.hanning(10)\n",
    "    from scipy.signal import convolve2d\n",
    "    smoothY=convolve2d(Y, kernel[:, np.newaxis], 'same')\n",
    "    abs_smoothY=abs(smoothY)\n",
    "    z=np.zeros(Y.shape[0])\n",
    "    for n in range(Y.shape[0]):\n",
    "        z[n]=np.mean(abs_smoothY[n])\n",
    "    ground=np.percentile(z, 1)\n",
    "    print(ground)\n",
    "    z=z-ground\n",
    "    return z/max(z)\n",
    "for i in range (nrOfDrums):\n",
    "    #print(framed.shape)\n",
    "    #Xpost[i].__class__ = madmom.audio.spectrogram.FilteredSpectrogram\n",
    "    #print(Xpost[i].ndim)\n",
    "    #diff=madmom.audio.spectrogram.SpectrogramDifference()\n",
    "    #superflux_3 = madmom.features.onsets.superflux(Xpost[i].T)\n",
    "    #superflux_3=superflux_3/(superflux_3.max(axis=0) )\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.imshow(Xpost[i], aspect='auto', origin='lower')\n",
    "    H[i]=superflux(W[i],H[i])\n",
    "    peaks=madmom.features.onsets.peak_picking(H[i],0.5)\n",
    "    \n",
    "    #kernel = np.hanning(29)\n",
    "    #kernel =np.kaiser(10,5)\n",
    "    #from scipy.signal import convolve\n",
    "    #H[i]=convolve(H[i], kernel, 'same')\n",
    "    plt.figure()\n",
    "    plt.plot((H[i]))\n",
    "    plt.vlines(peaks,0,max(H[i]))\n",
    "    #drums[i].set_frequency_pre(W.T[i])\n",
    "    \n",
    "   #z=smoothed_subband_mean((Xpost[i].T))\n",
    "   #peaks=madmom.features.onsets.peak_picking(z,0.5, pre_max=10)\n",
    "   #plt.figure()\n",
    "   #plt.plot(z)\n",
    "   #plt.vlines(peaks,0,max(z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def superflux(A,B):\n",
    "    spec_x=np.outer(A,B)\n",
    "    diff = np.zeros_like(spec_x.T)\n",
    "    size = (2,16)\n",
    "    max_spec = maximum_filter(spec_x.T, size=size)\n",
    "    diff[1:] = (spec_x.T[1:] - max_spec[: -1])\n",
    "    pos_diff = np.maximum(0, diff)\n",
    "    sf = np.sum(pos_diff, axis=1)\n",
    "    sf=sf/max(sf)\n",
    "    return sf\n",
    "\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "# widen the spectrogram in frequency dimension\n",
    "\n",
    "plt.figure()  \n",
    "plt.plot(H[7].T)\n",
    "sf=superflux(W[7],H[7])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sf)\n",
    "\n",
    "##log_filt_spec = madmom.audio.spectrogram.LogarithmicFilteredSpectrogram(spec_x.T, num_bands=24)\n",
    "##kernel = np.hanning(1)\n",
    "##from scipy.signal import convolve2d\n",
    "##smoothY=convolve2d(kick.T, kernel[:, np.newaxis], 'same')\n",
    "##kick=abs(smoothY.T)\n",
    "#\n",
    "#diff = np.zeros_like(spec_x.T)\n",
    "#size = (1,3)\n",
    "#max_spec = maximum_filter(spec_x.T, size=size)\n",
    "#diff[1:] = (spec_x.T[1:] - max_spec[: -1])\n",
    "#pos_diff = np.maximum(0, diff)\n",
    "#plt.figure()\n",
    "#plt.imshow(pos_diff.T, aspect='auto', origin='lower')\n",
    "#\n",
    "## keep only the positive differences\n",
    "#\n",
    "## sum everything to get the spectral flux\n",
    "#sf = np.sum(pos_diff, axis=1)\n",
    "#sf=sf/max(sf)\n",
    "##sf=sf/max(sf)\n",
    "##diff[Xpost[0].shape[1]:] = (Xpost[0][Xpost[0].shape[1]:]-diff_spec[:-Xpost[0].shape[1]])\n",
    "#plt.figure()  \n",
    "#plt.plot(sf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer=madmom.audio.Signal(\"./oikeetsamplet/drumBeat.wav\",frame_size=2048, hop_size=HOP_SIZE)\n",
    "filt_spec=get_preprocessed_spectrogram(buffer)\n",
    "clipped_frames=np.zeros_like(buffer)\n",
    "plt.figure()\n",
    "plt.plot(buffer)\n",
    "plt.figure()\n",
    "\n",
    "plt.imshow(filt_spec.T, aspect='auto', origin='lower')\n",
    "\n",
    "plt.figure()\n",
    "b=muLaw(filt_spec,mu=10**8).T\n",
    "plt.imshow(np.sqrt(b), aspect='auto', origin='lower')\n",
    "\n",
    "for i in range(len(buffer)): \n",
    "    \n",
    "    if buffer[i]==buffer[i-1]:\n",
    "        clipped_frames[i-1]=1\n",
    "print(len(clipped_frames[clipped_frames==1]))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    buffer=madmom.audio.Signal(\"./oikeetsamplet/drumBeat.wav\",frame_size=2084, hop_size=HOP_SIZE)\n",
    "    \n",
    "except Exception as e:\n",
    "    print (e)\n",
    "    print('jotain meni vikaan!')\n",
    "proc=madmom.audio.filters.BarkFilterbank(np.array(range(0,16384, 16)))\n",
    "filt_spec = madmom.audio.spectrogram.FilteredSpectrogram(buffer, filterbank=proc, sample_rate=44100, fmin=20)\n",
    "plt.figure()\n",
    "plt.imshow(1000000*filt_spec.T, aspect='auto', origin='lower')\n",
    "def muLaw(Y, frame_length=2048, hop_size=441, mu=10**8):\n",
    "    #n=frames, i=sub-bands\n",
    "    for n in range(Y.shape[0]):\n",
    "        for i in range(Y.shape[1]):\n",
    "            x_i_n=Y[n,i].flatten()@Y[n,i].flatten()\n",
    "            Y[n,i]= (np.log10(1+mu*x_i_n))/(np.log10(1+mu))\n",
    "    return Y\n",
    "filt_spec=filt_spec**2\n",
    "filt_spec=muLaw(filt_spec, mu=10**8)\n",
    "\n",
    "#filt_spec=muLaw(filt_spec, mu=10**8)\n",
    "#filt_spec=filt_spec**.5\n",
    "plt.figure()\n",
    "plt.imshow(filt_spec.T, aspect='auto', origin='lower')\n",
    "\n",
    "z=smoothed_subband_mean(filt_spec)**2\n",
    "peaks=madmom.features.onsets.peak_picking(z,0.5, pre_max=1)\n",
    "plt.figure()\n",
    "plt.plot(z)\n",
    "plt.vlines(peaks,0,max(z))\n",
    "#\n",
    "#nrOfDrums=9\n",
    "#HOP_SIZE=441\n",
    "#\"\"\"Jotain tähän tyyliin sitten sämplejä talteen\"\"\"\n",
    "#nrOfDrums=9\n",
    "#nrOfPeaks=32\n",
    "#nrOfDrumClasses=3\n",
    "#fpr=np.zeros((24, nrOfDrums))\n",
    "#frames=np.zeros((8192,nrOfDrums*nrOfPeaks))\n",
    "#drums=[]\n",
    "#list_X=[]\n",
    "#list_y=[]\n",
    "#def getPeaksFromBuffer(buffer, resolution, numHits, highEmph=0):\n",
    "#    proc=madmom.audio.filters.BarkFilterbank(np.array(range(0,16384, 16)))\n",
    "#    filt_spec = madmom.audio.spectrogram.FilteredSpectrogram(buffer, filterbank=proc, sample_rate=44100, fmin=10)\n",
    "#    def findDefBins(frames, filteredSpec):\n",
    "#        mod=PCA()\n",
    "#        mod2=FastICA(n_components=1)\n",
    "#        intermediateResult=[]\n",
    "#        topThree=np.array(mod.fit_transform(filteredSpec.T))\n",
    "#        icas=np.array(mod2.fit_transform(topThree[:,:3]))\n",
    "#        for j in range(icas.shape[1]):\n",
    "#            intermediateResult.append(icas[:,j])\n",
    "#           \n",
    "#        from sklearn.cluster import KMeans\n",
    "#        eigenDrum=[]\n",
    "#\n",
    "#        kmeans = KMeans(n_clusters=1, random_state=0).fit(intermediateResult)\n",
    "#        eigenDrum=kmeans.cluster_centers_\n",
    "#        return(eigenDrum)\n",
    "#\n",
    "#    log_filt_spec = madmom.audio.spectrogram.LogarithmicFilteredSpectrogram(buffer,num_bands=24,sample_rate=44100, fmin=10)\n",
    "#    superflux_3 = madmom.features.onsets.superflux(filt_spec)\n",
    "#    superflux_3=superflux_3/(superflux_3.max(axis=0) )\n",
    "#    threshold=1\n",
    "#    searchSpeed=0.2\n",
    "#    peaks=cleanDoubleStrokes(madmom.features.onsets.peak_picking(superflux_3,threshold),resolution)\n",
    "#    while(peaks.shape!=(numHits,)):\n",
    "#        #Make sure we don't go over numHits\n",
    "#        #There is a chance of an infinite loop here!!! Make sure that don't happen\n",
    "#        if(peaks.shape[0]>numHits):\n",
    "#            threshold+=searchSpeed\n",
    "#            searchSpeed=searchSpeed/2\n",
    "#        threshold-=searchSpeed\n",
    "#        peaks=cleanDoubleStrokes(madmom.features.onsets.peak_picking(superflux_3,threshold),resolution)\n",
    "#    buff=madmom.audio.spectrogram.LogarithmicFilteredSpectrogram(buffer, sample_rate=44100, fmin=5 ,num_bands=24)\n",
    "#    buffdiff = madmom.audio.spectrogram.SpectrogramDifference(filt_spec, positive_diffs=True, diff_max_bins=3)\n",
    "#    definingBins=findDefBins(peaks,buffdiff)\n",
    "#    return peaks, definingBins, threshold\n",
    "#            \n",
    "#                \n",
    "#          \n",
    "####Tässä pitää napata talteen framet/sample\n",
    "#for i in range(nrOfDrums):\n",
    "#    try:\n",
    "#        \n",
    "#        soundcheck=False\n",
    "#        print(\"./drum{}.wav\".format(i))\n",
    "#        buffer=madmom.audio.Signal(\"./oikeetsamplet/drum{}.wav\".format(i),frame_size=2048, hop_size=HOP_SIZE)\n",
    "#        CC1, fpr[:,i], threshold=getPeaksFromBuffer(buffer,1,nrOfPeaks,-1)\n",
    "#        plt.figure()\n",
    "#        plt.plot(fpr[:,i])\n",
    "#        fpr[:,i]=fpr[:,i]/fpr[:,i].max()\n",
    "#    except Exception as e: \n",
    "#        print(e)\n",
    "#        print('samples not found, please soundcheck!')\n",
    "#        print(\"Play drum nr. {}\".format(i+1))\n",
    "#        CC1, fpr[:,i], threshold, buffer= getStompTemplate(nrOfPeaks,recordingLength=2,highEmph=-1) \n",
    "#        outBuffer=unFrameSignal(buffer)\n",
    "#        madmom.io.audio.write_wave_file(buffer, './drum{}.wav'.format(i),sample_rate=44100)\n",
    "#    if(True):\n",
    "#        templates=[]\n",
    "#        samples=[]\n",
    "#        midinotes=[36,38,42,46,50,45,51,49,40]\n",
    "#        def ZCR(signal):\n",
    "#            ZC=0\n",
    "#            for i in range(1,signal.shape[0]):\n",
    "#                if np.sign(signal[i-1])!=np.sign(signal[i]):\n",
    "#                    ZC+=1\n",
    "#            return ZC\n",
    "#        \n",
    "#        for j in range(len(CC1)):\n",
    "#            #print(CC1[j])\n",
    "#            time=CC1[j]\n",
    "#            tinyBuff=madmom.audio.signal.signal_frame(buffer,time, frame_size=4*HOP_SIZE, hop_size=HOP_SIZE, origin=0)\n",
    "#            fiba=madmom.audio.spectrogram.FilteredSpectrogram(tinyBuff,filterbank=MelFilterbank,sample_rate=44100)\n",
    "#            mfcc2=madmom.audio.cepstrogram.MFCC(fiba, num_bands=32, mul=5, add=2)\n",
    "#            mfcc_delta = librosa.feature.delta(mfcc2)\n",
    "#            feats=np.append(mfcc2[0],[mfcc2[1],mfcc2[2],mfcc2[3], mfcc_delta[0], mfcc_delta[1]])\n",
    "#            templates.append(np.append(feats,[np.append([ZCR(tinyBuff)], \n",
    "#                                                        [np.append([scipy.stats.kurtosis(tinyBuff)]\n",
    "#                                                                   ,[np.append([scipy.stats.skew(tinyBuff)],[spectral_centroid(tinyBuff)])])])]))\n",
    "#            samples.append(tinyBuff) #8192 for 4 frames\n",
    "#           \n",
    "#        drums.append(Drum(name=[i],templates=templates, samples=samples, threshold=threshold, midinote=midinotes[i]))\n",
    "#try:\n",
    "#\n",
    "#    buffer=madmom.audio.Signal(\"./oikeetsamplet/drumBeat.wav\",frame_size=2048, hop_size=HOP_SIZE)\n",
    "#    \n",
    "#except Exception as e:\n",
    "#    print (e)\n",
    "#    print('jotain meni vikaan!')\n",
    "#proc=madmom.audio.filters.BarkFilterbank(np.array(range(0,16384, 16)))\n",
    "#filt_spec = madmom.audio.spectrogram.FilteredSpectrogram(buffer, filterbank=proc, sample_rate=44100)\n",
    "#Y = madmom.audio.spectrogram.SpectrogramDifference(filt_spec, positive_diffs=True, diff_max_bins=3)\n",
    "#Y=abs(Y)\n",
    "#plt.figure()\n",
    "#plt.imshow(Y.T, aspect='auto', origin='lower')\n",
    "#fpp=np.linalg.pinv(fpr)\n",
    "#for i in range (nrOfDrums):\n",
    "#    plt.figure()\n",
    "#    plt.plot(fpr[i])\n",
    "###Multiplying the overall spectrogram by the pseudo-inverse of the prior frequency subspaces yield estimates of the amplitude basis functions, tˆ :\n",
    "###The pseudo inverse is wrong??? Better or equal results with just a transpose??\n",
    "#tHat=np.dot(fpp,Y.T).T\n",
    "##print(tHat.min())\n",
    "#for i in range (nrOfDrums):\n",
    "#    plt.figure()\n",
    "#    plt.plot(tHat[:,i])\n",
    "#    \n",
    "#ica = FastICA(n_components=nrOfDrums)\n",
    "#t = (ica.fit_transform(tHat))\n",
    "##t2=t\n",
    "#print(t.shape)\n",
    "#for i in range (nrOfDrums):\n",
    "#    plt.figure()\n",
    "#    plt.plot((t[:,i]))\n",
    "#plt.figure()\n",
    "#plt.plot(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import resample\n",
    "\n",
    "n_samples=2**17\n",
    "#n_samples=len(list_y)\n",
    "#bootsrap extra samples by resampling with replacement\n",
    "random_state=0\n",
    "X,y=resample(np.array(list_X),np.array(list_y), n_samples=n_samples)\n",
    "#X_train,y_train=resample(np.array(X[:int(n_samples*0.9)]),np.array(y[:int(n_samples*0.9)]),n_samples=n_samples*10)\n",
    "scaler=preprocessing.MinMaxScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "#print(X_train.shape)\n",
    "X_train, y_train = X[:n_samples*0.8], y[:n_samples*0.8]\n",
    "X_train_valid, y_train_valid = X[:n_samples*0.9], y[:n_samples*0.9]\n",
    "X_valid, y_valid = X[n_samples*0.8:n_samples*0.9], y[n_samples*0.8:n_samples*0.9]\n",
    "X_test, y_test = X[n_samples*0.9:], y[n_samples*0.9:]\n",
    "#X_test, y_test = resample(np.array(X[int(n_samples*0.9):]),np.array(y[int(n_samples*0.9):]),n_samples=n_samples)\n",
    "#X_test=scaler.fit_transform(X_test)\n",
    "#train_X, train_y=[np.array(list_X),np.array(list_y)]\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_valid = lgb.Dataset(X_test, y_test)\n",
    "print(np.unique(y_train).shape)\n",
    "num_labels = np.unique(y_train).shape[0]\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_leaves': 9,\n",
    "    'learning_rate': 0.5,\n",
    "    'max_depth':1,\n",
    "    'max_bin': 516, \n",
    "    'subsample_for_bin': 100,\n",
    "    'subsample': 1, \n",
    "    'subsample_freq': 100, \n",
    "    'colsample_bytree': 0.9, \n",
    "    'reg_alpha': 0.01, \n",
    "    'reg_lambda': 0.01,\n",
    "    'min_split_gain': 0.5, \n",
    "    'min_child_weight': 5, \n",
    "    'min_child_samples': 5, \n",
    "    'scale_pos_weight':100,\n",
    "    #'feature_fraction': 0.5,\n",
    "    #'bagging_fraction': 0.5,\n",
    "    #'bagging_freq': 2,\n",
    "    'verbose': 1,\n",
    "    'device':'cpu',\n",
    "    'num_threads':8,\n",
    "    #'min_data':1,\n",
    "    #'min_data_in_bin':1,\n",
    "    'num_class':num_labels\n",
    "}\n",
    "print('Start training...')\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "        lgb_train,\n",
    "        num_boost_round=300,\n",
    "        valid_sets=[lgb_valid],\n",
    "        early_stopping_rounds=100, verbose_eval=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.mixture import GaussianMixture\n",
    "n_samples=2**14\n",
    "#n_samples=len(list_y)\n",
    "#bootsrap extra samples by resampling with replacement\n",
    "X,y=resample(np.array(list_X),np.array(list_y),n_samples=n_samples, random_state=0)\n",
    "scaler=preprocessing.MinMaxScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X_train, y_train = X[:n_samples*0.8], y[:n_samples*0.8]\n",
    "X_train_valid, y_train_valid = X[:n_samples*0.9], y[:n_samples*0.9]\n",
    "X_valid, y_valid = X[n_samples*0.8:n_samples*0.9], y[n_samples*0.8:n_samples*0.9]\n",
    "X_test, y_test = X[n_samples*0.9:], y[n_samples*0.9:]\n",
    "#X,y=resample(np.array(list_X),np.array(list_y), replace=False)\n",
    "#X_train,y_train=resample(np.array(X[:int(n_samples*0.9)]),np.array(y[:int(n_samples*0.9)]),n_samples=n_samples*10)\n",
    "#scaler=preprocessing.MinMaxScaler()\n",
    "#X_train=scaler.fit_transform(X_train)\n",
    "#X_test, y_test = resample(np.array(X[int(n_samples*0.9):]),np.array(y[int(n_samples*0.9):]),n_samples=n_samples)\n",
    "#X_test=scaler.fit_transform(X_test)\n",
    "n_classes = np.unique(y_train).shape[0]\n",
    "from time import time\n",
    "t0=time()\n",
    "#n_estimators = 20\n",
    "#svc = BaggingClassifier(KNeighborsClassifier(n_neighbors=nrOfDrums,n_jobs=-1, leaf_size=5), max_samples=1.0 / n_estimators, n_estimators=n_estimators, n_jobs=-1)\n",
    "#svc.fit(X_train, y_train)\n",
    "#preds_SVC=svc.predict_proba(X_test)\n",
    "#score = log_loss(y_test, preds_SVC)\n",
    "#print('SVM ',score)\n",
    "#print ('SVM time:%0.2f' %(time()-t0))\n",
    "#X,y=resample(np.array(list_X),np.array(list_y),n_samples=n_samples)\n",
    "#scaler=preprocessing.MinMaxScaler()\n",
    "#X=scaler.fit_transform(X)\n",
    "#X_train, y_train = X[:n_samples*0.8], y[:n_samples*0.8]\n",
    "#X_train_valid, y_train_valid = X[:n_samples*0.9], y[:n_samples*0.9]\n",
    "#X_valid, y_valid = X[n_samples*0.8:n_samples*0.9], y[n_samples*0.8:n_samples*0.9]\n",
    "#X_test, y_test = X[n_samples*0.9:], y[n_samples*0.9:]\n",
    "#t0=time()           \n",
    "##\n",
    "proc=madmom.audio.filters.BarkFilterbank(np.array(range(0,16384, 16)))\n",
    "#clf = RandomForestClassifier(n_estimators=1234,n_jobs=-1, verbose=0, criterion='entropy')\n",
    "clf = KNeighborsClassifier(n_neighbors=nrOfDrums,n_jobs=-1, leaf_size=5)\n",
    "##\n",
    "clf.fit(X_train, y_train)\n",
    "print ('CLF time:%0.2f' %(time()-t0))\n",
    "t0=time()\n",
    "preds_CLF=clf.predict_proba(X_test)\n",
    "\n",
    "#for i in range(preds_CLF.shape[0]):\n",
    "#    preds_CLF[i]=preds_CLF[i]/max(preds_CLF[i])\n",
    "score = log_loss(y_test, preds_CLF)\n",
    "print('CLF ',score)\n",
    "\n",
    "t0=time() \n",
    "GMM = GaussianMixture(n_components=nrOfDrums)\n",
    "GMM.fit(X_train, y_train)\n",
    "print ('GMM time:%0.2f' %(time()-t0))\n",
    "t0=time()\n",
    "preds_GMM=GMM.predict_proba(X_test)\n",
    "\n",
    "#for i in range(preds_CLF.shape[0]):\n",
    "#    preds_CLF[i]=preds_CLF[i]/max(preds_CLF[i])\n",
    "score = log_loss(y_test, preds_GMM)\n",
    "print('GMM ',score)\n",
    "preds_CNN=cnn.predict(X_test)\n",
    "#for i in range(preds_CNN.shape[0]):\n",
    "#     preds_CNN[i]=preds_CNN[i]/max(preds_CNN[i])\n",
    "#print (preds_CNN)\n",
    "score = log_loss(y_test, preds_CNN)\n",
    "print('CNN ',score)\n",
    "\n",
    "#preds_LGB=gbm.predict(X_test)\n",
    "#for i in range(preds_LGB.shape[0]):\n",
    "#    preds_LGB[i]=preds_LGB[i]/max(preds_LGB[i])\n",
    "#score = log_loss(y_test, preds_LGB)\n",
    "#print('LGB ',score)\n",
    "\n",
    "\n",
    "\n",
    "#preds_SVC=svc.predict_proba(X_test)\n",
    "#score = log_loss(y_test, preds_SVC)\n",
    "#print('SVM ',score)\n",
    "#\n",
    "preds_CNN=(preds_CNN+preds_CLF)\n",
    "#print (clf_probs.shape)\n",
    "score = log_loss(y_test, preds_CNN)\n",
    "print(score)\n",
    "print ('preds time:%0.2f' %(time()-t0))\n",
    "t0=time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import madmom\n",
    "HOP_SIZE=441\n",
    "print('KOMPPIA! (lopeta ctrl+C)')\n",
    "buffer=np.zeros(HOP_SIZE)\n",
    "try:\n",
    "    strm=madmom.audio.signal.Stream(sample_rate=44100, num_channels=1,frame_size=2048, hop_size=HOP_SIZE)\n",
    "    for i in strm:\n",
    "            buffer=np.append(buffer,[i[:HOP_SIZE]])\n",
    "            #print(buffer.shape)\n",
    "except:\n",
    "    print(buffer.shape)\n",
    "    madmom.io.audio.write_wave_file(buffer, './drumBeat.wav',sample_rate=44100)\n",
    "    print('vittu')\n",
    "print(\"morjens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proc=madmom.audio.filters.BarkFilterbank(np.array(range(0,16384, 16)))\n",
    "filt_spec = madmom.audio.spectrogram.FilteredSpectrogram(buffer, filterbank=proc, sample_rate=44100)\n",
    "Y = madmom.audio.spectrogram.SpectrogramDifference(filt_spec, positive_diffs=True, diff_max_bins=3)\n",
    "\n",
    "Yl=Y\n",
    "Y=abs(Y)\n",
    "Pe=np.ones(Y.shape[1])\n",
    "for i in range(Y.shape[1]-1):\n",
    "    Yl[:,i+1]=20*np.log10(Y[:,i]/Y[:,i+1])\n",
    "    Pe[i]=sum(Yl[:,i+1]>0.5)\n",
    "plt.figure()\n",
    "plt.imshow(abs(Yl.T), aspect='auto', origin='lower')\n",
    "plt.figure()\n",
    "plt.plot(Pe)\n",
    "Y = madmom.audio.spectrogram.SpectrogramDifference(filt_spec, positive_diffs=True, diff_max_bins=3)\n",
    "plt.figure()\n",
    "plt.imshow(Y.T, aspect='auto', origin='lower')\n",
    "print(Yl[774, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print('KOMPPIA!')\n",
    "#CC4, f4, treshold, buff4=getStompTemplate(32, recordingLength=2)\n",
    "import madmom\n",
    "import numpy as np\n",
    "import madmom.audio.cepstrogram\n",
    "from madmom.audio.filters import MelFilterbank\n",
    "from madmom.audio.filters import RectangularFilterbank\n",
    "from sklearn.decomposition import FastICA, NMF\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import pyaudio\n",
    "import time\n",
    "import scipy\n",
    "nrOfDrums=9\n",
    "HOP_SIZE=441\n",
    "try:\n",
    "\n",
    "    buffer=madmom.audio.Signal(\"./oikeetsamplet/drumTest.wav\",frame_size=2048, hop_size=HOP_SIZE)\n",
    "    \n",
    "except Exception as e:\n",
    "    print (e)\n",
    "    print('jotain meni vikaan!')\n",
    "proc=madmom.audio.filters.BarkFilterbank(np.array(range(0,16384, 16)))\n",
    "filt_spec = madmom.audio.spectrogram.FilteredSpectrogram(buffer, filterbank=proc, sample_rate=44100)\n",
    "Y = madmom.audio.spectrogram.SpectrogramDifference(filt_spec, positive_diffs=True, diff_max_bins=3)\n",
    "Y=abs(Y)\n",
    "#Y = np.log(1+np.dot(2,Y))\n",
    "#sf = madmom.features.onsets.superflux(Yl)\n",
    "#sf=sf/(sf.max(axis=0))\n",
    "#plt.figure()\n",
    "#plt.plot(sf)\n",
    "#Yl = np.log(1+np.dot(250,Y))\n",
    "#sf = madmom.features.onsets.superflux(Yl)\n",
    "#sf=sf/(sf.max(axis=0))\n",
    "#plt.figure()\n",
    "#plt.plot(sf)\n",
    "#Yl = np.log(1+np.dot(500,Y))\n",
    "#print (Yl.shape)\n",
    "#sf = madmom.features.onsets.superflux(Yl)\n",
    "#sf=sf/(sf.max(axis=0))\n",
    "#plt.figure()\n",
    "#plt.plot(sf)\n",
    "#Y = madmom.audio.spectrogram.SpectrogramDifference(madmom.audio.spectrogram.LogarithmicFilteredSpectrogram(buffer, sample_rate=44100, fmin=5 ,num_bands=24), positive_diffs=True, diff_max_bins=3)\n",
    "#Yl = np.log(1+np.dot(500,Y))\n",
    "#Yl=Y\n",
    "#log_filt_spec = madmom.audio.spectrogram.LogarithmicFilteredSpectrogram(buff4,num_bands=24,sample_rate=44100, fmin=1, fmax=22050)\n",
    "#superflux_3 = madmom.features.onsets.superflux(filt_spec)\n",
    "#superflux_3=superflux_3/(superflux_3.max(axis=0) )\n",
    "#Y = buff4\n",
    "#fpp=np.linalg.pinv(fpr)\n",
    "#plt.figure()\n",
    "#plt.imshow(Y.T, aspect='auto', origin='lower')\n",
    "#\n",
    "#print(Y.min())\n",
    "#print(fpp.max())\n",
    "#print(fpp.min())\n",
    "#Multiplying the overall spectrogram by the pseudo-inverse of the prior frequency subspaces yield estimates of the amplitude basis functions, tˆ :\n",
    "#The pseudo inverse is wrong??? Better or equal results with just a transpose??\n",
    "#tHat=np.dot(fpp,Y.T).T\n",
    "#print(tHat.min())\n",
    "#for i in range (nrOfDrums):\n",
    "#    plt.figure()\n",
    "#    plt.plot(tHat[:,i]/max(tHat[:,i]))\n",
    "###However the estimated amplitude basis functions returned are not independent and so ICA is carried out on tˆ to give:\n",
    "#ica = FastICA(n_components=nrOfDrums)\n",
    "#t = (ica.fit_transform(tHat))\n",
    "#t2=t\n",
    "#print(t.shape)\n",
    "#plt.figure()\n",
    "#plt.plot(t)\n",
    "#for i in range (nrOfDrums):\n",
    "#    ##Change to positive and move base to 0\n",
    "#    #if abs(t[:,i].min())>t[:,i].max():\n",
    "#    #    t[:,i]=-1*t[:,i]\n",
    "#    ##t[:,i][t[:,i]<0]=0\n",
    "#    #t[:,i]=t[:,i]+(abs(t[:,i].min(axis=0)))\n",
    "#    ##Normalize\n",
    "#    ##mean(a(i:i+n-1)),1:n:length(a)-n+1)'; % the averaged vector\n",
    "#    #\n",
    "#    ##t=abs(t)\n",
    "#    #t[:,i]=(t[:,i]/(t[:,i].max(axis=0)))\n",
    "#    #Plot for sanity check\n",
    "#    n=20\n",
    "#    for j in range(len(t[:,i])-n+1):\n",
    "#        t2[j,i]=np.mean(t[j:j+n,i])\n",
    "#        \n",
    "#    plt.figure()\n",
    "#    #plt.plot(t[:,i])\n",
    "#    plt.plot((t2[:,i]))\n",
    "#    \n",
    "#Improved estimates of the frequency basis functions can then be obtained from\n",
    "#where tp is the pseudo-inverse of t. \n",
    "#tp=np.linalg.pinv(t)\n",
    "#\n",
    "#f=(np.dot(Y.T,tp.T))\n",
    "##f=f/f.max()\n",
    "#fpp=np.linalg.pinv(f)\n",
    "#tHat=np.dot(fpp,Y.T).T\n",
    "#\n",
    "#print(tHat.min())\n",
    "#for i in range (nrOfDrums):\n",
    "#    #n=20\n",
    "#    #for j in range(len(tHat[:,i])-n+1):\n",
    "#    #    tHat[j,i]=np.mean(tHat[j:j+n,i])\n",
    "#    plt.figure()\n",
    "#    plt.plot((tHat[:,i]))\n",
    "#    \n",
    "#plt.figure()\n",
    "#plt.plot(f)\n",
    "#print(tp.shape)\n",
    "#print(f.shape)\n",
    "##The independent spectrograms can then be individually obtained from:\n",
    "##for i in range(nrOfDrums):\n",
    "##    plt.figure()\n",
    "##    A=np.outer(f.T[i],tp[i])\n",
    "##    A=A/A.max()\n",
    "##    plt.imshow(A, aspect='auto', origin='lower')\n",
    "#plt.figure()\n",
    "#plt.plot((np.dot(f.T, Y.T)).T)\n",
    "\n",
    "#NMF\n",
    "model = NMF(n_components=9, init='custom', random_state=0,solver='mu',beta_loss='kullback-leibler')\n",
    "W = model.fit_transform(Y.T, W=abs(fpr), H=abs(np.random.normal(0,10,[nrOfDrums,Y.shape[0]])))\n",
    "##W=model.fit_transform(Y.T)\n",
    "H= model.components_\n",
    "\n",
    "#HHat=np.dot(W.T, Y.T).T\n",
    "Membranes=[1,1,0,0,1,1,0,0,0]\n",
    "\n",
    "#for i in range(nrOfDrums):\n",
    "#    \n",
    "#    if Membranes[i]==1:\n",
    "#        W[40:,i]=0\n",
    "#    else:\n",
    "#        W[:120,i]=0\n",
    "#    W[:,i]=W[:,i]/W[:,i].max()\n",
    "    \n",
    "##print (W.shape)\n",
    "max_idx=0\n",
    "for i in range(nrOfDrums):\n",
    "    proc=madmom.audio.filters.BarkFilterbank(np.array(range(0,16384, 16)))\n",
    "    filt_spec = madmom.audio.spectrogram.FilteredSpectrogram(np.ravel(drums[i].get_samples()), filterbank=proc, sample_rate=44100)\n",
    "    Y = madmom.audio.spectrogram.SpectrogramDifference(filt_spec, positive_diffs=True, diff_max_bins=3)\n",
    "    \n",
    "    HHat=np.dot(W.T, Y.T).T\n",
    "    HHat=HHat/HHat.max(axis=0)\n",
    "    \n",
    "    superflux_3 = madmom.features.onsets.superflux(Y)\n",
    "    #superflux_3=superflux_3/(superflux_3.max(axis=0) )\n",
    "    peaks=madmom.features.onsets.peak_picking(superflux_3,drums[i].get_threshold())\n",
    "    thr=drums[i].get_threshold()\n",
    "    #print(peaks.mean(axis=0))\n",
    "    print(peaks)\n",
    "    print(HHat[peaks].mean(axis=0))\n",
    "    \n",
    "    max_idx = np.argmax(HHat[peaks].mean(axis=0))\n",
    "    print (max_idx)\n",
    "    drums[i].set_frequency_pre(W[:,max_idx])\n",
    "    plt.figure()\n",
    "    plt.plot(HHat[:,max_idx])\n",
    "    plt.hlines(thr, xmin=0, xmax=HHat.shape[0])\n",
    "    plt.ylabel(max_idx)\n",
    "    plt.figure()\n",
    "    plt.plot(HHat[:,i])\n",
    "    plt.hlines(thr, xmin=0, xmax=HHat.shape[0])\n",
    "    plt.ylabel(i)\n",
    "    \n",
    "    #for j in range(W.shape[1]):\n",
    "    #    \n",
    "    #    if np.linalg.norm(fpr[:,i]-W[:,j])<=np.linalg.norm(fpr[:,i]-closest):\n",
    "    #        closest=W[:,j]\n",
    "    \n",
    "\n",
    "\n",
    "#for i in range(nrOfDrums):\n",
    "#    print((W[:,i]))\n",
    "#    (W[:,i])=(W[:,i] == W[:,i].max()).astype(int)\n",
    "#    plt.figure()\n",
    "#    plt.plot((W[:,i]))\n",
    "#    plt.figure()\n",
    "#    A=np.outer(W[i],HHat.T[i])\n",
    "#    A=A/A.max()\n",
    "#    plt.imshow(A, aspect='auto', origin='lower')\n",
    "#W=(W == W.max(axis=1)[:,None]).astype(int)\n",
    "\n",
    "for i in range (nrOfDrums):\n",
    "    #n=20\n",
    "    #for j in range(len(HHat[:,i])-n+1):\n",
    "    #    HHat[j,i]=np.mean(HHat[j:j+n,i])\n",
    "    plt.figure()\n",
    "    plt.plot((W[:,i]))\n",
    "    plt.ylabel(i)\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(H[i,:])\n",
    "    plt.ylabel(i)\n",
    "    \n",
    "#for i in range(nrOfDrums):\n",
    "#    plt.figure()\n",
    "#    A=np.outer(W[i],HHat.T[i])\n",
    "#    plt.imshow(A, aspect='auto', origin='lower')\n",
    "    \n",
    "### tee list_X ja list_y täsä drumseista.\n",
    "#print((drums[0].get_templates()))\n",
    "list_X=[]\n",
    "list_y=[]\n",
    "for i in drums:\n",
    "    #one for every template the drum has stored\n",
    "    for j in i.get_templates():\n",
    "        #one for every drum present in the template\n",
    "        a=np.ravel(i.get_name())\n",
    "        for k in range(len(a)):\n",
    "            list_X.append(j)\n",
    "            list_y.append(a[k])\n",
    "\n",
    "print(len(list_X[0]))\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import sgd as SGD\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Convolution2D, Convolution1D, GRU, LSTM,BatchNormalization\n",
    "from keras.layers import MaxPooling2D, MaxPooling1D, AveragePooling2D\n",
    "from keras.layers import Flatten, Input\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "from os import listdir\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "from sklearn.utils import resample\n",
    "##list_X=[]\n",
    "##list_y=[]\n",
    "##for j in range(nrOfPeaks):\n",
    "##           frames[:,i*16+j]=np.ravel(CC1[j])\n",
    "##for i in range(nrOfDrums*nrOfPeaks):\n",
    "##    print(lb.feature.mfcc(frames[:,i],sr=44100,n_mfcc=1).shape)\n",
    "##    list_X.extend([np.reshape(lb.feature.mfcc(frames[:,i],sr=44100,n_mfcc=32),544)])\n",
    "##    list_y.extend([int(i/16)])\n",
    "\n",
    "#bootsrap extra samples by resampling with replacement\n",
    "train_X,train_y=resample(np.array(list_X),np.array(list_y),n_samples=2**13)\n",
    "random_state = np.random.get_state()\n",
    "np.random.shuffle(train_X)\n",
    "np.random.set_state(random_state)\n",
    "np.random.shuffle(train_y)\n",
    "train_y=keras.utils.np_utils.to_categorical(train_y)\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "num_labels = train_y.shape[1]\n",
    "model = Sequential()\n",
    "act = ELU(input_shape=(train_X.shape[1],))\n",
    "# model.add(Dropout(0.2, input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(32, input_shape=(train_X.shape[1],), init='he_normal'))\n",
    "# model.add(act)\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, init='he_normal', activation='relu'))\n",
    "# model.add(act)\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, init='lecun_uniform', activation='relu'))\n",
    "# model.add(act)\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, init='normal', activation='relu'))\n",
    "model.add(Dense(num_labels, init='lecun_uniform', activation=\"softmax\"))\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "modelsaver=ModelCheckpoint(filepath=\"weights_testivedot.hdf5\", verbose=1, save_best_only=True)\n",
    "earlystopper=EarlyStopping(monitor=\"val_loss\", patience=100, mode='auto')\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='nadam')\n",
    "#model.fit(train_X, train_y,batch_size=1024, nb_epoch=500\n",
    "#          , callbacks=[modelsaver,earlystopper]\n",
    "#          ,validation_split=0.1\n",
    "#          ,verbose=2)\n",
    "#model.load_weights(\"weights_testivedot.hdf5\")\n",
    "#print(\"Loaded model from disk\")\n",
    "#preds = model.predict(X_val)\n",
    "#model.save('keras.model_testivedot.h5')\n",
    "#print('Model saved to disk.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "for i in range(nrOfDrums):\n",
    "    plt.figure()\n",
    "    A=np.outer(W.T[i],HHat.T[i])\n",
    "    A=librosa.power_to_db(A)\n",
    "    plt.imshow(A, aspect='auto', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import MaxPooling1D, MaxPooling2D\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "import time\n",
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from scipy.io.wavfile import read, write\n",
    "from keras.activations import relu\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Convolution1D, AtrousConvolution1D, Flatten, Dense, Input, Lambda, merge, Activation\n",
    "modType=5\n",
    "#train_X=np.array(list_X)\n",
    "#train_y=np.array(list_y)\n",
    "#random_state = np.random.get_state()\n",
    "#np.random.shuffle(train_X)\n",
    "#np.random.set_state(random_state)\n",
    "#np.random.shuffle(train_y)\n",
    "#train_y=keras.utils.np_utils.to_categorical(train_y)\n",
    "#num_labels = train_y.shape[1]\n",
    "#print(train_X.shape)\n",
    "train_X,train_y=resample(np.array(list_X),np.array(list_y),n_samples=2**14)\n",
    "random_state = np.random.get_state()\n",
    "np.random.shuffle(train_X)\n",
    "np.random.set_state(random_state)\n",
    "np.random.shuffle(train_y)\n",
    "train_y=keras.utils.np_utils.to_categorical(train_y)\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "num_labels = train_y.shape[1]\n",
    "\n",
    "\n",
    "    \n",
    "if modType==1:\n",
    "    train_X = train_X.reshape(train_X.shape[0], train_X.shape[1], 1)\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(32,3, activation='relu', input_shape=(train_X.shape[1],1)))\n",
    "    model.add(Convolution1D(32,3, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(GRU(512, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Convolution1D(64,3, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Convolution1D(64,3, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Convolution1D(32, 3, activation='relu'))\n",
    "    model.add(Convolution1D(32, 3, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(num_labels, activation='softmax'))\n",
    "    print(model.summary())\n",
    "if modType==2:\n",
    "    train_X = train_X.reshape(train_X.shape[0], 14,14, 1)\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(14, 3, 3, activation='relu', input_shape=(14, 14, 1)))\n",
    "    model.add(Convolution2D(14, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    #model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_labels, activation='softmax'))\n",
    "    print(model.summary())\n",
    "if modType==3:\n",
    "    model = Sequential()\n",
    "    #act = ELU(input_shape=(train_X.shape[1],))\n",
    "    # model.add(Dropout(0.2, input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(196, input_shape=(train_X.shape[1],), init='he_normal'))\n",
    "    # model.add(act)\n",
    "    #model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(256, init='he_normal', activation='relu'))\n",
    "    # model.add(act)\n",
    "   # model.add(Dropout(0.2))\n",
    "    #model.add(Dense(128, init='lecun_uniform', activation='relu'))\n",
    "    # model.add(act)\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(64, init='normal', activation='relu'))\n",
    "    model.add(Dense(num_labels, init='lecun_uniform', activation=\"softmax\"))\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    print(model.summary())\n",
    "embedding_dim = 1\n",
    "if modType==4:\n",
    "    train_X = train_X.reshape(train_X.shape[0], train_X.shape[1], 1)\n",
    "    model = Sequential()\n",
    "    #model.add(Embedding(train_y.shape[1], embedding_dim, input_length=196))\n",
    "    model.add(GRU(2, return_sequences=True, input_shape=(train_X.shape[1],1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(GRU(2, return_sequences=True))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_labels, init='lecun_uniform', activation=\"softmax\"))\n",
    "    #model.add(TimeDistributedDense(1, init='lecun_uniform', activation=\"softmax\"))\n",
    "    #model.add(TimeDistributedDense(1))\n",
    "    #model.add(Activation('softmax'))\n",
    "    print(model.summary())\n",
    "    \n",
    "#wavenet\n",
    "if modType==5:\n",
    "    train_X = train_X.reshape(train_X.shape[0], train_X.shape[1], 1)\n",
    "    def wavenetBlock(n_atrous_filters, atrous_filter_size, atrous_rate):\n",
    "        def f(input_):\n",
    "            residual = input_\n",
    "            tanh_out = AtrousConvolution1D(n_atrous_filters, atrous_filter_size,\n",
    "                                           atrous_rate=atrous_rate,\n",
    "                                           border_mode='same',\n",
    "                                           activation='tanh')(input_)\n",
    "            sigmoid_out = AtrousConvolution1D(n_atrous_filters, atrous_filter_size,\n",
    "                                              atrous_rate=atrous_rate,\n",
    "                                              border_mode='same',\n",
    "                                              activation='sigmoid')(input_)\n",
    "            merged = merge([tanh_out, sigmoid_out], mode='mul')\n",
    "            skip_out = Convolution1D(1, 1, activation='relu', border_mode='same')(merged)\n",
    "            out = merge([skip_out, residual], mode='sum')\n",
    "            return out, skip_out\n",
    "        return f\n",
    "    def get_basic_generative_model(input_size):\n",
    "        input_ = Input(shape=(input_size, 1))\n",
    "        A, B = wavenetBlock(2560, 2, 2)(input_)\n",
    "        skip_connections = [B]\n",
    "        for i in range(4):\n",
    "            A, B = wavenetBlock(102, 2, 2**((i+2)%9))(A)\n",
    "            skip_connections.append(B)\n",
    "        net = merge(skip_connections, mode='sum')\n",
    "        net = Activation('relu')(net)\n",
    "        net = Convolution1D(1, 1, activation='relu')(net)\n",
    "        net = Convolution1D(1, 1)(net)\n",
    "        net = Flatten()(net)\n",
    "        net = Dense(num_labels, activation='softmax')(net)\n",
    "        model = Model(input=input_, output=net)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='sgd',\n",
    "                      metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        return model\n",
    "    model=get_basic_generative_model(train_X.shape[1])\n",
    "    print(model.summary())\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "modelsaver=ModelCheckpoint(filepath=\"weights_testivedot2.hdf5\", verbose=1, save_best_only=True)\n",
    "earlystopper=EarlyStopping(monitor=\"val_loss\", patience=100, mode='auto')\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='nadam')\n",
    "model.fit(train_X, train_y,batch_size=128, epochs=2000\n",
    "          , callbacks=[modelsaver,earlystopper]\n",
    "          ,validation_split=0.1\n",
    "          ,verbose=1)\n",
    "\n",
    "model.load_weights(\"weights_testivedot2.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    "#preds = model.predict(X_val)\n",
    "model.save('keras.model_testivedot2.h5')\n",
    "print('Model saved to disk.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=madmom.io.midi.MIDIFile.from_notes(df.values)\n",
    "#print (t.shape)\n",
    "madmom.io.midi.write_midi(df.values,'midi_testit.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "FREQUENCY_PRE=[0,16384]#0-2^14\n",
    "MIDINOTE=36 #kickdrum in most systems\n",
    "THRESHOLD=0.5 \n",
    "PROBABILITY_THRESHOLD=0.5\n",
    "\n",
    "class Drum(object):\n",
    "    \"\"\"\n",
    "    A Drum is any user playable drumkit part representation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : String\n",
    "        Name of the drum\n",
    "    frequency_pre : list, optional\n",
    "        corner frequencies of drum signal\n",
    "    midinote: int, optional\n",
    "        midi note representing the drum\n",
    "    threshold : float, optional\n",
    "        onset detection threshold.\n",
    "    probability_threshold : float, optional\n",
    "        NN prediction threshold.\n",
    "    \n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Unfinished class, work in progress\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, name=NAME, frequency_pre=FREQUENCY_PRE,\n",
    "                 midinote=MIDINOTE, threshold=THRESHOLD, probability_threshold=PROBABILITY_THRESHOLD\n",
    "                 ,**kwargs):\n",
    "        \n",
    "        # set attributes\n",
    "        self.name = name\n",
    "        if frequency_pre:\n",
    "            self.frequency_pre = frequency_pre\n",
    "        else:\n",
    "            self.frequency_pre = [0,22050]\n",
    "        if midinote:\n",
    "            self.midinote= int(midinote)\n",
    "        if threshold:\n",
    "            self.threshold = float(threshold)\n",
    "        if probability_threshold:\n",
    "            self.probability_threshold=float(probability_threshold)\n",
    "    def set_frequency_pre(frequency_pre):\n",
    "        self.frequency_pre=float(frequency_pre)\n",
    "    def get_frequency_pre(self):\n",
    "        return self.frequency_pre  \n",
    "    def set_midinote(midinote):\n",
    "        self.midinote=float(midinote)\n",
    "    def get_midinote(self):\n",
    "        return self.midinote\n",
    "    def set_midinote(midinote):\n",
    "        self.threshold=float(threshold)\n",
    "    def get_threshold(self):\n",
    "        return self.threshold\n",
    "    def set_probability_threshold(probability_threshold):\n",
    "        self.probability_threshold=float(probability_threshold)\n",
    "    def get_probability_threshold(self):\n",
    "        return self.probability_threshold\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import madmom\n",
    "import numpy as np\n",
    "import madmom.audio.cepstrogram\n",
    "from madmom.audio.filters import MelFilterbank\n",
    "from madmom.audio.filters import RectangularFilterbank\n",
    "from sklearn.decomposition import PCA, FastICA, NMF\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import pyaudio\n",
    "import time\n",
    "import scipy\n",
    "\n",
    "FRAME_SIZE=2048\n",
    "HOP_SIZE=441\n",
    "SAMPLE_RATE=44100\n",
    "FREQUENCY_PRE=np.ones((24))#[0,16384]#0-2^14\n",
    "MIDINOTE=36 #kickdrum in most systems\n",
    "THRESHOLD=0.0 \n",
    "PROBABILITY_THRESHOLD=0.0\n",
    "proc=madmom.audio.filters.BarkFilterbank(madmom.audio.stft.fft_frequencies(num_fft_bins=int(FRAME_SIZE/2), sample_rate=SAMPLE_RATE) ,num_bands='normal')\n",
    "#proc=madmom.audio.filters.LogarithmicFilterbank(num_bands=24)\n",
    "class Drum(object):\n",
    "    \"\"\"\n",
    "    A Drum is any user playable drumkit part representation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : String\n",
    "        Name of the drum\n",
    "    frequency_pre : list, optional\n",
    "        corner frequencies of drum signal\n",
    "    midinote: int, optional\n",
    "        midi note representing the drum\n",
    "    threshold : float, optional\n",
    "        onset detection threshold.\n",
    "    probability_threshold : float, optional\n",
    "        NN prediction threshold.\n",
    "    \n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Unfinished class, work in progress\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, name,highEmph, samples=None,templates=None, frequency_pre=FREQUENCY_PRE,\n",
    "                 midinote=MIDINOTE, threshold=THRESHOLD, probability_threshold=PROBABILITY_THRESHOLD\n",
    "                 ,**kwargs):\n",
    "        \n",
    "        # set attributes\n",
    "        self.name = name\n",
    "        self.highEmph=highEmph\n",
    "        if len(frequency_pre):\n",
    "            self.frequency_pre = frequency_pre\n",
    "        if len(samples):\n",
    "            self.samples = samples\n",
    "        if len(templates):\n",
    "            self.templates=templates\n",
    "        if midinote:\n",
    "            self.midinote=midinote\n",
    "        if threshold:\n",
    "            self.threshold = float(threshold)\n",
    "        if probability_threshold:\n",
    "            self.probability_threshold=float(probability_threshold)\n",
    "    def set_name(self,name):\n",
    "        self.name=name\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    def set_highEmph(self,highEmph):\n",
    "        self.highEmph=highEmph\n",
    "    def get_highEmph(self):\n",
    "        return self.highEmph\n",
    "    def set_templates(self,templates):\n",
    "        self.templates=templates\n",
    "    def get_templates(self):\n",
    "        return self.templates \n",
    "    def set_samples(self,samples):\n",
    "        self.samples=samples\n",
    "    def get_samples(self):\n",
    "        return self.samples\n",
    "    def set_frequency_pre(self,frequency_pre):\n",
    "        self.frequency_pre=frequency_pre\n",
    "    def get_frequency_pre(self):\n",
    "        return self.frequency_pre  \n",
    "    def set_midinote(self,midinote):\n",
    "        self.midinote=int(midinote)\n",
    "    def get_midinote(self):\n",
    "        return self.midinote\n",
    "    def set_threshold(self,threshold):\n",
    "        self.threshold=float(threshold)\n",
    "    def get_threshold(self):\n",
    "        return self.threshold\n",
    "    def set_probability_threshold(self,probability_threshold):\n",
    "        self.probability_threshold=float(probability_threshold)\n",
    "    def get_probability_threshold(self):\n",
    "        return self.probability_threshold\n",
    "\n",
    "#live audio\n",
    "print('noniin')\n",
    "\n",
    "#From https://stackoverflow.com/questions/24354279/python-spectral-centroid-for-a-wav-file\n",
    "def spectral_centroid(x, samplerate=44100):\n",
    "    magnitudes = np.abs(np.fft.rfft(x)) # magnitudes of positive frequencies\n",
    "    length = len(x)\n",
    "    freqs = np.abs(np.fft.fftfreq(length, 1.0/samplerate)[:length//2+1]) # positive frequencies\n",
    "    return np.log(np.sum(magnitudes*freqs) / np.sum(magnitudes))\n",
    "def ZCR(signal):\n",
    "    ZC=0\n",
    "    for i in range(1,signal.shape[0]):\n",
    "        if np.sign(signal[i-1])!=np.sign(signal[i]):\n",
    "            ZC+=1\n",
    "    return ZC\n",
    "#brickwall limiter to even out high peaks\n",
    "def limitToPercentile(data, limit=90, lowlimit=10, ratio=1):\n",
    "    limit=np.percentile(data,limit)\n",
    "    lowlimit=np.percentile(data,lowlimit)\n",
    "    highPeaks = abs(data) > limit # Where values higher than the percentile\n",
    "    data[highPeaks] = limit #brickwall the signal to the limit\n",
    "    lowPeaks = abs(data) < lowlimit # Where values higher than the percentile\n",
    "    data[lowPeaks] = np.sign(data[lowPeaks])*lowlimit #brickwall the signal to the limit\n",
    "    return (data)\n",
    "def cleanDoubleStrokes(hitList, resolution=10):\n",
    "        retList=[]\n",
    "        lastSeenHit=0\n",
    "        for i in range(len(hitList)):\n",
    "            if hitList[i]>=lastSeenHit+resolution:\n",
    "                retList.append(hitList[i])\n",
    "                lastSeenHit=hitList[i]\n",
    "        return (np.array(retList))\n",
    "##Pitäiskö laittaa toi gäppi kans määriteltäväksi??    \n",
    "def filter_emphasis(spectro,highEmph):\n",
    "    dummy=np.zeros_like(spectro)\n",
    "    #print(filt_spec[:,-5:].shape)\n",
    "    if(highEmph==-1):\n",
    "        dummy[:,:5]=spectro[:,:5]\n",
    "    elif(highEmph==0):\n",
    "        dummy[:,2:7]=spectro[:,2:7]\n",
    "    elif(highEmph==1):\n",
    "        dummy[:,-5:]=spectro[:,-5:]\n",
    "    elif(highEmph==2):\n",
    "        dummy=spectro\n",
    "    return dummy\n",
    "#def muLaw(Y, frame_length=2048, hop_size=441, mu=10**8):\n",
    "#    x_mu=np.zeros_like(Y)\n",
    "#    #for i in range(Y.shape[0]):\n",
    "#    #    x_mu[i] = np.sign(Y[i]) * np.log(1 + mu*np.abs(Y[i]))/np.log(1 + mu)\n",
    "#    #return ((x_mu + 1)/2 * mu)\n",
    "#    ##n=frames, i=sub-bands\n",
    "#    \n",
    "#    for n in range(Y.shape[0]):\n",
    "#        for i in range(Y.shape[1]):\n",
    "#            x_i_n=Y[n,i]\n",
    "#            x_mu[n,i]= (np.log(1+mu*x_i_n))/(np.log(1+mu))\n",
    "#    return x_mu\n",
    "\n",
    "def muLaw(Y, mu=10**8):\n",
    "    #n=frames, i=sub-bands\n",
    "    x_mu=np.zeros_like(Y)\n",
    "\n",
    "    for n in range(Y.shape[0]):\n",
    "        for i in range(Y.shape[1]):\n",
    "            #x_i_n=Y[n,i].flatten()@Y[n,i].flatten()\n",
    "            x_i_n=Y[n,i]\n",
    "            x_mu[n,i]= np.sign(Y[n,i]) * np.log(1 + mu * x_i_n)/np.log(1 + mu)\n",
    "    return x_mu\n",
    "def get_preprocessed_spectrogram(buffer):\n",
    "    buffer=buffer/max(buffer)\n",
    "    spec=madmom.audio.spectrogram.FilteredSpectrogram(buffer, filterbank=proc, sample_rate=SAMPLE_RATE,frame_size=FRAME_SIZE, hop_size=HOP_SIZE, fmin=20)\n",
    "    #spec=muLaw(spec,mu=10**8)\n",
    "    spec=spec/spec.max()\n",
    "    return spec\n",
    "\n",
    "#Too hard coded method- refine generality\n",
    "def generate_features(signal, highEmph):\n",
    "    features=[]\n",
    "    try:    \n",
    "        #fiba=madmom.audio.spectrogram.FilteredSpectrogram(signal,filterbank=proc,sample_rate=44100, f_min=10)\n",
    "        fiba=get_preprocessed_spectrogram(signal)\n",
    "        fiba2=filter_emphasis(fiba, highEmph)\n",
    "        mfcc2=madmom.audio.cepstrogram.MFCC(fiba2, num_bands=32)\n",
    "        mfcc_delta = librosa.feature.delta(mfcc2)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc2, order=2)\n",
    "\n",
    "        feats=np.append(mfcc2[0],[mfcc2[1],mfcc2[2],mfcc2[3], mfcc_delta[0], mfcc_delta[1]])\n",
    "        features=(np.append(feats,[np.append([ZCR(signal)]\n",
    "                                                   , [np.append([scipy.stats.kurtosis(signal)]\n",
    "                                                        ,[np.append([scipy.stats.skew(signal)]\n",
    "                                                            ,[spectral_centroid(signal)])])])])) \n",
    "        \n",
    "    except Exception as e:\n",
    "        print('feature error:',e)\n",
    "        \"\"\"muista panna paddia alkuun ja loppuun\"\"\" \n",
    "        \n",
    "    return features\n",
    "def make_sample(signal, time, n_frames):\n",
    "    sample=madmom.audio.signal.signal_frame(signal,time, frame_size=n_frames*HOP_SIZE, hop_size=HOP_SIZE, origin=0)\n",
    "    sample=madmom.audio.signal.normalize(sample)\n",
    "    return sample\n",
    "def add_to_samples_and_dictionary(drum, signal, times):\n",
    "    for i in times:\n",
    "        sample=make_sample(signal, i,n_frames=4)\n",
    "        drum.get_samples().append(sample)\n",
    "        drum.get_templates().append(generate_features(sample, drum.get_highEmph()))\n",
    "def getPeaksFromBuffer(buffer, resolution, numHits, highEmph=0):\n",
    "    #proc=madmom.audio.filters.BarkFilterbank(np.array(range(0,16384, 16)))\n",
    "    #########################Tähän tein muutoksia eli bark veke ja back takas.\n",
    "    #filt_spec = madmom.audio.spectrogram.FilteredSpectrogram(buffer, filterbank=proc, sample_rate=44100, fmin=20)\n",
    "    #filt_spec=filter_emphasis(filt_spec, highEmph)\n",
    "    #filt_spec=muLaw(filt_spec, mu=1)\n",
    "    #filt_spec=madmom.audio.Spectrogram(buffer)\n",
    "    filt_spec=get_preprocessed_spectrogram(buffer)\n",
    "    def findDefBins(frames, filteredSpec):\n",
    "        #mod3=NMF(n_components=2)\n",
    "        #intermediateResult=[]\n",
    "        #topThree=np.array(mod.fit_transform(filteredSpec.T))\n",
    "        #icas=np.array(mod2.fit_transform(topThree))\n",
    "        #icas=np.array(mod3.fit_transform(filteredSpec[frames].T))\n",
    "        #intermediateResult.append(icas[:,1])\n",
    "        #from sklearn.cluster import KMeans\n",
    "        #eigenDrum=[]\n",
    "        \n",
    "        #return sum(filteredSpec[:])\n",
    "        #kmeans = KMeans(n_clusters=1, random_state=0).fit(intermediateResult)\n",
    "        #eigenDrum=kmeans.cluster_centers_\n",
    "        #return(icas[:,0]) \n",
    "        \n",
    "        #Capture frames around the onset.\n",
    "        gaps=np.zeros(frames.shape[0]*10)\n",
    "        tailgaps=np.zeros(frames.shape[0]*10)\n",
    "        n_frames=4\n",
    "        for i in range(frames.shape[0]):\n",
    "            #gaps[i*n_frames]=frames[i]-3\n",
    "            #gaps[(i*n_frames)+1]=frames[i]-2\n",
    "            gaps[(i*n_frames)+2]=frames[i]-1\n",
    "            gaps[(i*n_frames)+3]=frames[i]\n",
    "            gaps[(i*n_frames)+4]=frames[i]+1\n",
    "            gaps[(i*n_frames)+5]=frames[i]+2\n",
    "            if highEmph==1:\n",
    "                print('hi')\n",
    "                gaps[(i*n_frames)+6]=frames[i]+3\n",
    "                gaps[(i*n_frames)+7]=frames[i]+4\n",
    "                gaps[(i*n_frames)+8]=frames[i]+5\n",
    "                gaps[(i*n_frames)+9]=frames[i]+6\n",
    "                gaps[(i*n_frames)]=frames[i]+7\n",
    "                gaps[(i*n_frames)+1]=frames[i]+8\n",
    "#\n",
    "            #tailgaps[i*n_frames]=frames[i]+7\n",
    "            #tailgaps[(i*n_frames)+1]=frames[i]+8\n",
    "            #tailgaps[(i*n_frames)+2]=frames[i]+9\n",
    "            #tailgaps[(i*n_frames)+3]=frames[i]+10\n",
    "            #tailgaps[(i*n_frames)+4]=frames[i]+11\n",
    "            #tailgaps[(i*n_frames)+5]=frames[i]+12\n",
    "            #tailgaps[(i*n_frames)+6]=frames[i]+13\n",
    "            #tailgaps[(i*n_frames)+7]=frames[i]+14\n",
    "            #tailgaps[(i*n_frames)+8]=frames[i]+15\n",
    "            #tailgaps[(i*n_frames)+9]=frames[i]+16\n",
    "        heads=np.mean(filteredSpec[gaps.astype(int)].T, axis=1)\n",
    "        tailgaps=np.ones(filteredSpec.shape[0])\n",
    "        tailgaps[gaps.astype(int)]=0\n",
    "        tails=(np.mean(filteredSpec[tailgaps==1].T, axis=1))\n",
    "        #tails=(np.mean(filteredSpec[tailgaps.astype(int)].T, axis=1))\n",
    "        return(heads, tails)\n",
    "        #heads=np.mean(filteredSpec.T, axis=1)\n",
    "        #return(heads, tails)\n",
    "        #return(np.mean(filteredSpec[gaps.astype(int)].T, axis=1),np.mean(filteredSpec[-gaps.astype(int)].T, axis=1))\n",
    "    \n",
    "    #superflux_3 = madmom.features.onsets.superflux(muLaw(filt_spec,mu=10**8))\n",
    "    #kernel = np.hanning(3)\n",
    "    ##kernel =np.kaiser(10,5)\n",
    "    #from scipy.signal import convolve\n",
    "    #superflux_3=convolve(superflux_3, kernel, 'same')\n",
    "    superflux_3 = madmom.features.onsets.superflux(filt_spec)\n",
    "    superflux_3=superflux_3/(superflux_3.max(axis=0) )\n",
    "    #plt.figure()\n",
    "    #plt.plot(superflux_3)\n",
    "    threshold=1\n",
    "    searchSpeed=0.2\n",
    "    peaks=cleanDoubleStrokes(madmom.features.onsets.peak_picking(superflux_3,threshold),resolution)\n",
    "    #print('luuppiin')\n",
    "    #print(peaks)\n",
    "    while(peaks.shape!=(numHits,)):\n",
    "        #Make sure we don't go over numHits\n",
    "        #There is a chance of an infinite loop here!!! Make sure that don't happen\n",
    "        if(peaks.shape[0]>numHits):\n",
    "            threshold+=searchSpeed\n",
    "            searchSpeed=searchSpeed/2\n",
    "        threshold-=searchSpeed\n",
    "        peaks=cleanDoubleStrokes(madmom.features.onsets.peak_picking(superflux_3,threshold),resolution)\n",
    "     \n",
    "    #buff=madmom.audio.spectrogram.LogarithmicFilteredSpectrogram(buffer, sample_rate=44100, fmin=5 ,num_bands=24)\n",
    "    #buffdiff = madmom.audio.spectrogram.SpectrogramDifference(filt_spec, positive_diffs=True, diff_max_bins=3)\n",
    "\n",
    "    definingBins=findDefBins(peaks,filt_spec)\n",
    "    return peaks, definingBins, threshold\n",
    "    #return peaks, np.zeros(24), threshold\n",
    "def playSample(data):\n",
    "    # instantiate PyAudio (1)\n",
    "    p = pyaudio.PyAudio()\n",
    "    # open stream (2)\n",
    "    stream = p.open(format=pyaudio.paFloat32,\n",
    "                    frames_per_buffer=HOP_SIZE,\n",
    "                    channels=1,\n",
    "                    rate=44100,\n",
    "                    output=True)\n",
    "    # play stream (3)\n",
    "    f=0\n",
    "    print(len(data))\n",
    "    while data!='':\n",
    "        stream.write(data[f])\n",
    "        f+=1\n",
    "        if f>=len(data):\n",
    "            break\n",
    "\n",
    "    # stop stream (4)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    \n",
    "    # close PyAudio (5)\n",
    "    p.terminate()\n",
    "\n",
    "def getStompTemplate(numHits=2, recordingLength=1, highEmph=0):\n",
    "    \"\"\"\n",
    "    Kutsutaan pari kertaa, eka vaikka kaks ja sit neljä iskua talteen\n",
    "    Niiden pohjalta lasketaan olennaisin taajuus ja threshold\n",
    "    \"\"\"\n",
    "    stompResolution=1\n",
    "    buffer=np.zeros(shape=(227792*recordingLength))\n",
    "    j=0\n",
    "    strm=madmom.audio.signal.Stream(sample_rate=44100, num_channels=1,frame_size=2048, hop_size=HOP_SIZE)\n",
    "    for i in strm:\n",
    "            #print(i.shape)\n",
    "            buffer[j:j+HOP_SIZE]=i[:HOP_SIZE]\n",
    "            j+=HOP_SIZE\n",
    "            if j>=221792*recordingLength:\n",
    "                buffer[j:j+6000]=np.zeros(6000)\n",
    "                #buffer=madmom.audio.signal.normalize(buffer)\n",
    "                peaks, bins, threshold=getPeaksFromBuffer(buffer, stompResolution,numHits, highEmph=highEmph) \n",
    "                \n",
    "                strm.close()\n",
    "                return peaks, bins,threshold, buffer\n",
    "                \n",
    "\n",
    "\n",
    "menevaan=False\n",
    "\"\"\"Jotain tähän tyyliin sitten sämplejä talteen\"\"\"\n",
    "nrOfDrums=9\n",
    "nrOfPeaks=32\n",
    "nrOfDrumClasses=3\n",
    "fpr=np.zeros((proc.shape[1], nrOfDrums*2))\n",
    "frames=np.zeros((8192,nrOfDrums*nrOfPeaks))\n",
    "drums=[]\n",
    "list_X=[]\n",
    "list_y=[]\n",
    "NoneTemplates=[]\n",
    "highEmph=[-1,0,0,1,0,0,1,1,0]\n",
    "#highEmph=[2,2,2,2,2,2,2,2,2]\n",
    "###Tässä pitää napata talteen framet/sample\n",
    "for i in range(nrOfDrums):\n",
    "    try:\n",
    "        \n",
    "        soundcheck=False\n",
    "        print(\"./oikeetsamplet/drum{}.wav\".format(i))\n",
    "        buffer=madmom.audio.Signal(\"./oikeetsamplet/drum{}.wav\".format(i),frame_size=2048, hop_size=HOP_SIZE)\n",
    "        CC1, freqtemps, threshold=getPeaksFromBuffer(buffer,1,nrOfPeaks,highEmph=highEmph[i])\n",
    "        fpr[:,i]=freqtemps[0]\n",
    "        fpr[:,i+nrOfDrums]=freqtemps[1]\n",
    "        #print(fpr[:,i])\n",
    "        #fpr[:,i]=fpr[:,i]/fpr[:,i].max()\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        print('samples not found, please soundcheck!')\n",
    "        print(\"Play drum nr. {}\".format(i+1))\n",
    "        CC1, freqtemps, threshold, buffer= getStompTemplate(nrOfPeaks,recordingLength=2,highEmph=highEmph[i]) \n",
    "        #outBuffer=unFrameSignal(buffer)\n",
    "        madmom.io.audio.write_wave_file(buffer, './drum{}.wav'.format(i),sample_rate=44100)\n",
    "    if(True):\n",
    "        #print(\"Play drum nr. {}\".format(i+1))\n",
    "        #CC1, fpr[:,i], threshold, buffer= getStompTemplate(nrOfPeaks,recordingLength=2,highEmph=-1) \n",
    "        #outBuffer=unFrameSignal(buffer)\n",
    "        #madmom.io.audio.write_wave_file(outBuffer, './drum{}.wav'.format(i),sample_rate=44100)\n",
    "        ##mel_spec=madmom.audio.cepstrogram.MFCC(madmom.audio.spectrogram.FilteredSpectrogram(buffer,filterbank=MelFilterbank, sample_rate=44100), num_bands=32)\n",
    "        templates=[]\n",
    "        samples=[]\n",
    "        midinotes=[36,38,42,46,50,45,51,49,40] #BD, SN, CHH, OHH, TT, FT, RD, CR, SHH\n",
    "        \n",
    "        \n",
    "        for j in range(len(CC1)):\n",
    "            #print(CC1[j])\n",
    "            time=CC1[j]\n",
    "            #zeroFound=0\n",
    "            #pointer=1\n",
    "            #while not zeroFound:\n",
    "            #    if (buffer[CC1[j]]<=0 and buffer[CC1[j]+1]>0):\n",
    "            #        zeroFound=True\n",
    "            #        break\n",
    "            #    elif (buffer[CC1[j]+pointer]<=0 and buffer[CC1[j]+pointer+1]>0):\n",
    "            #        zeroFound=True\n",
    "            #        CC1[j]=CC1[j]+pointer\n",
    "            #        break\n",
    "            #    elif (buffer[CC1[j]-(pointer+1)]<=0 and buffer[CC1[j]-pointer]>0):\n",
    "            #        zeroFound=True\n",
    "            #        CC1[j]=CC1[j]-(pointer+1)\n",
    "            #        break\n",
    "            #    pointer+=1\n",
    "                \n",
    "            tinyBuff=make_sample(buffer, time, n_frames=4)\n",
    "            templates.append(generate_features(tinyBuff, highEmph[i]))\n",
    "            #tinyBuff=madmom.audio.signal.signal_frame(buffer,time+7, frame_size=4*HOP_SIZE, hop_size=HOP_SIZE, origin=0)\n",
    "            #fiba=madmom.audio.spectrogram.FilteredSpectrogram(tinyBuff,filterbank=MelFilterbank,sample_rate=44100)\n",
    "            #mfcc2=madmom.audio.cepstrogram.MFCC(fiba, num_bands=32, mul=5, add=2)\n",
    "            #mfcc_delta = librosa.feature.delta(mfcc2)\n",
    "            #feats_None=np.append(mfcc2[0],[mfcc2[1],mfcc2[2],mfcc2[3], mfcc_delta[0], mfcc_delta[1]])\n",
    "            ##feats=np.append(mel_spec[time],[mel_spec[time+1],mel_spec[time+2],mel_spec[time+3]])\n",
    "            #NoneTemplates.append(np.append(feats_None,[np.append([ZCR(tinyBuff)], \n",
    "            #                                            [np.append([scipy.stats.kurtosis(tinyBuff)]\n",
    "            #                                                       ,[np.append([scipy.stats.skew(tinyBuff)],[spectral_centroid(tinyBuff)])])])]))\n",
    "            #print(templates)\n",
    "            #sample=madmom.audio.signal.signal_frame(buffer,[time:time+3], frame_size=2048, hop_size=HOP_SIZE, origin=0)\n",
    "            samples.append(tinyBuff) #8192 for 4 frames\n",
    "            ##samples=np.append(buffer[time:time+HOP_SIZE],[buffer[time+1],buffer[time+2],buffer[time+3]])\n",
    "            ##print(samples[0].shape)\n",
    "            #fiba=madmom.audio.spectrogram.FilteredSpectrogram(samples,filterbank=MelFilterbank,sample_rate=44100)\n",
    "            ##print(fiba.shape)\n",
    "            #mfcc2=madmom.audio.cepstrogram.MFCC(fiba, num_bands=32)\n",
    "            #testi=np.append(mfcc2[0],[mfcc2[1],mfcc2[2],mfcc2[3]])\n",
    "            #print(np.linalg.norm(feats-testi))\n",
    "            \n",
    "        drums.append(Drum(name=[i], highEmph=highEmph[i],templates=templates, samples=samples, threshold=threshold, midinote=midinotes[i], probability_threshold=1))\n",
    "#drums.append(Drum(name=[nrOfDrums],templates=NoneTemplates, samples=samples, threshold=1, midinote=0, probability_threshold=1))\n",
    "\n",
    "'''generate artificial samples where multiple drums are hit at the same time, store as Drum objects'''\n",
    "\n",
    "def generateNewSample(drums):\n",
    "    samplesA=drums[0].get_samples()\n",
    "    samplesB=drums[1].get_samples()\n",
    "    samplesC=[]\n",
    "    for i in range(min([len(samplesA), len(samplesB)])):\n",
    "        samplesC.append((.5*samplesA[i])+(.5*samplesB[i]))\n",
    "    #print(samplesC)\n",
    "    samplesC=np.array(samplesC)\n",
    "    #samplesC=samplesC/samplesC.max()\n",
    "    #mel_spec=madmom.audio.cepstrogram.MFCC(madmom.audio.spectrogram.FilteredSpectrogram(np.ravel(samplesC),filterbank=MelFilterbank, sample_rate=44100), num_bands=32)\n",
    "\n",
    "    #mel_spec=librosa.feature.mfcc(np.ravel(samplesC),sr=44100,n_mfcc=32)\n",
    "    \n",
    "    templatesC=[]\n",
    "    highEmphA=drums[0].get_highEmph()\n",
    "    highEmphB=drums[1].get_highEmph()\n",
    "    if highEmphA==highEmphB:\n",
    "        for j in range(len(samplesC)):\n",
    "            templatesC.append(generate_features(samplesC[j], highEmph))\n",
    "            \n",
    "    #Jos ei highemph täsmää tehdään puolet toista ja puolet toista.        \n",
    "    else:\n",
    "        for j in range(int(len(samplesC)/2)):\n",
    "            templatesC.append(generate_features(samplesC[j], highEmphA))\n",
    "            templatesC.append(generate_features(samplesC[-j], highEmphB))\n",
    "            \n",
    "    return Drum([drums[0].get_name(),drums[1].get_name()],0,templates=templatesC, samples=[], midinote=[])  \n",
    "\n",
    "from itertools import combinations, permutations\n",
    "newDrums=combinations(drums[:nrOfDrums], 2)\n",
    "for i in newDrums:\n",
    "    drums.append(generateNewSample(i))\n",
    "    #print(generateNewSample(i).get_name())\n",
    "#freq_pre sen mukaan mitä alussa tehtiin, ei sen kummempaa NMF hommaa enää\n",
    "#for i in range(nrOfDrums):\n",
    "#    drums[i].set_frequency_pre(fpr[:,i])\n",
    "#\n",
    "try:\n",
    "        \n",
    "    soundcheck=False\n",
    "    buffer=madmom.audio.Signal(\"./oikeetsamplet/drumBeat.wav\".format(i),frame_size=2048, hop_size=HOP_SIZE)\n",
    "    \n",
    "except:\n",
    "    print('samples not found, please soundcheck!')\n",
    "    print(\"Play a drum beat\")\n",
    "    CC1, frequencies, threshold, buffer= getStompTemplate(nrOfPeaks,recordingLength=4,highEmph=-1) \n",
    "    madmom.io.audio.write_wave_file(buffer, './oikeetsamplet/drumBeat.wav'.format(i),sample_rate=44100)\n",
    "    print('joo joo, voit lopettaa jo')\n",
    "\n",
    "#Y = madmom.audio.spectrogram.SpectrogramDifference(madmom.audio.spectrogram.LogarithmicFilteredSpectrogram(buffer, sample_rate=44100, fmin=5 ,num_bands=24), positive_diffs=True, diff_max_bins=3)\n",
    "#Yl = np.log(1+np.dot(500,Y))\n",
    "#proc=madmom.audio.filters.BarkFilterbank(np.array(range(0,16384, 16)))\n",
    "#    #proc=MelFilterbank(MelFilterFreq, fmin=0.0, fmax=22050.0, norm_filters=True, unique_filters=True)\n",
    "#    \n",
    "#\n",
    "#filt_spec = madmom.audio.spectrogram.FilteredSpectrogram(buffer, filterbank=proc, sample_rate=44100)\n",
    "#Y = madmom.audio.spectrogram.SpectrogramDifference(filt_spec)\n",
    "#Y=abs(Y)\n",
    "##\n",
    "###fpr=fpr/fpr.max()\n",
    "#fpp=np.linalg.pinv(fpr)\n",
    "##fpp=fpp+fpp.min()*-1\n",
    "#\n",
    "##Y=madmom.audio.spectrogram.Spectrogram(buff4, include_nyqvist=True)\n",
    "#buff=madmom.audio.spectrogram.LogarithmicFilteredSpectrogram(buff4, sample_rate=44100, fmin=5 ,num_bands=24)\n",
    "#Y = madmom.audio.spectrogram.SpectrogramDifference(buff, positive_diffs=True, diff_max_bins=3)\n",
    "#RectFilterFreq=[150,166,1500,6500,8066,17000, 22050]\n",
    "#print('KOMPPIA!')\n",
    "#CC4, f4, treshold, buff4=getStompTemplate(64, recordingLength=2)\n",
    "#BarkFilterFreq=[100, 200, 300, 400, 510, 630, 770, 920, 1080, 1270, 1480, 1720, 2000, 2320, 2700, 3150, 3700, 4400, 5300, 6400, 7700, 9500, 12000]\n",
    "#proc = RectangularFilterbank(np.array(range(0,16384, 16)),BarkFilterFreq\n",
    "#                                 , fmin=0.0, fmax=15500.0, norm_filters=True, unique_filters=True)\n",
    "#print(proc.shape)\n",
    "#proc=madmom.audio.filters.BarkFilterbank(np.array(range(0,16384, 16)))\n",
    "#print(proc.shape)\n",
    "#filt_spec = madmom.audio.spectrogram.FilteredSpectrogram(buff4, filterbank=proc, sample_rate=44100)\n",
    "#Y = madmom.audio.spectrogram.SpectrogramDifference(filt_spec, positive_diffs=True, diff_max_bins=3)\n",
    "#try:\n",
    "#    madmom.io.audio.write_wave_file(buff4, './drumTest.wav',sample_rate=44100)\n",
    "#except:\n",
    "#    print('vittu')\n",
    "##plt.figure()\n",
    "##plt.imshow(Y.T, aspect='auto', origin='lower')\n",
    "##\n",
    "##print(Y.min())\n",
    "##print(fpp.max())\n",
    "##print(fpp.min())\n",
    "##Multiplying the overall spectrogram by the pseudo-inverse of the prior frequency subspaces yield estimates of the amplitude basis functions, tˆ :\n",
    "##The pseudo inverse is wrong??? Better or equal results with just a transpose??\n",
    "#tHat=np.dot(fpp,Y.T).T\n",
    "#print(tHat.min())\n",
    "#for i in range (nrOfDrums):\n",
    "#    plt.figure()\n",
    "#    plt.plot(tHat[:,i]/max(tHat[:,i]))\n",
    "###However the estimated amplitude basis functions returned are not independent and so ICA is carried out on tˆ to give:\n",
    "#ica = FastICA(n_components=nrOfDrums)\n",
    "#t = (ica.fit_transform(tHat))\n",
    "#t2=t\n",
    "##print(t.shape)\n",
    "##plt.figure()\n",
    "##plt.plot(t)\n",
    "#for i in range (nrOfDrums):\n",
    "#    ##Change to positive and move base to 0\n",
    "#    #if abs(t[:,i].min())>t[:,i].max():\n",
    "#    #    t[:,i]=-1*t[:,i]\n",
    "#    ##t[:,i][t[:,i]<0]=0\n",
    "#    #t[:,i]=t[:,i]+(abs(t[:,i].min(axis=0)))\n",
    "#    ##Normalize\n",
    "#    ##mean(a(i:i+n-1)),1:n:length(a)-n+1)'; % the averaged vector\n",
    "#    #\n",
    "#    ##t=abs(t)\n",
    "#    #t[:,i]=(t[:,i]/(t[:,i].max(axis=0)))\n",
    "#    #Plot for sanity check\n",
    "#    n=20\n",
    "#    for j in range(len(t[:,i])-n+1):\n",
    "#        t2[j,i]=np.mean(t[j:j+n,i])\n",
    "#        \n",
    "#    plt.figure()\n",
    "#    #plt.plot(t[:,i])\n",
    "#    plt.plot((t2[:,i]))\n",
    "#    \n",
    "#Improved estimates of the frequency basis functions can then be obtained from\n",
    "#where tp is the pseudo-inverse of t. \n",
    "#tp=np.linalg.pinv(t)\n",
    "#\n",
    "#f=(np.dot(Y.T,tp.T))\n",
    "##f=f/f.max()\n",
    "#fpp=np.linalg.pinv(f)\n",
    "#tHat=np.dot(fpp,Y.T).T\n",
    "#\n",
    "#print(tHat.min())\n",
    "#for i in range (nrOfDrums):\n",
    "#    #n=20\n",
    "#    #for j in range(len(tHat[:,i])-n+1):\n",
    "#    #    tHat[j,i]=np.mean(tHat[j:j+n,i])\n",
    "#    plt.figure()\n",
    "#    plt.plot((tHat[:,i]))\n",
    "#    \n",
    "#plt.figure()\n",
    "#plt.plot(f)\n",
    "#print(tp.shape)\n",
    "#print(f.shape)\n",
    "##The independent spectrograms can then be individually obtained from:\n",
    "##for i in range(nrOfDrums):\n",
    "##    plt.figure()\n",
    "##    A=np.outer(f.T[i],tp[i])\n",
    "##    A=A/A.max()\n",
    "##    plt.imshow(A, aspect='auto', origin='lower')\n",
    "#plt.figure()\n",
    "#plt.plot((np.dot(f.T, Y.T)).T)\n",
    "\n",
    "#NMF\n",
    "#model = NMF(n_components=nrOfDrums*2, init='custom', random_state=0,solver='mu',beta_loss='kullback-leibler')\n",
    "#W = model.fit_transform(Y.T, W=abs(fpr), H=abs(np.random.normal(0,10,[nrOfDrums*2,Y.shape[0]])))\n",
    "###W= model.fit_transform(Y.T)\n",
    "#H= model.components_\n",
    "#for i in range(nrOfDrums):\n",
    "#    drums[i].set_frequency_pre(W.T[i])\n",
    "##match freq pre to drums\n",
    "#for i in range(nrOfDrums):\n",
    "#    proc=madmom.audio.filters.BarkFilterbank(np.array(range(0,16384, 16)))\n",
    "#    filt_spec = madmom.audio.spectrogram.FilteredSpectrogram(np.ravel(drums[i].get_samples()), filterbank=proc, sample_rate=44100)\n",
    "#    filt_spec2=filter_emphasis(filt_spec, drums[i].get_highEmph())\n",
    "#    Y = madmom.audio.spectrogram.SpectrogramDifference(filt_spec2, positive_diffs=True, diff_max_bins=3)\n",
    "#    #Y = madmom.audio.spectrogram.SpectrogramDifference(filt_spec, positive_diffs=True, diff_max_bins=3)\n",
    "#    HHat=np.dot(W.T, Y.T).T\n",
    "#    HHat=HHat/HHat.max(axis=0)\n",
    "#    superflux_3 = madmom.features.onsets.superflux(Y)\n",
    "#    peaks=madmom.features.onsets.peak_picking(superflux_3,drums[i].get_threshold())\n",
    "#    max_idx = np.argmax(HHat[peaks].mean(axis=0))\n",
    "#    drums[i].set_frequency_pre(W.T[i])\n",
    "    \n",
    "#print (W.shape)\n",
    "#for i in range(nrOfDrums):\n",
    "#    #closest=W[:,0]\n",
    "#    #for j in range(W.shape[1]):\n",
    "#     #   if np.linalg.norm(fpr[:,i]-W[:,j])<=np.linalg.norm(fpr[:,i]-closest):\n",
    "#     #       closest=W[:,j]\n",
    "#    drums[i].set_frequency_pre(W[:,i])\n",
    "#\n",
    "#\n",
    "#for i in range(nrOfDrums):\n",
    "#    print((W[:,i]))\n",
    "#    (W[:,i])=(W[:,i] == W[:,i].max()).astype(int)\n",
    "#    plt.figure()\n",
    "#    plt.plot((W[:,i]))\n",
    "#    plt.figure()\n",
    "#    A=np.outer(W[i],HHat.T[i])\n",
    "#    A=A/A.max()\n",
    "#    plt.imshow(A, aspect='auto', origin='lower')\n",
    "##W=(W == W.max(axis=1)[:,None]).astype(int)\n",
    "#HHat=np.dot(W.T, Y.T).T\n",
    "#print(W.shape, HHat.shape)\n",
    "#for i in range (nrOfDrums):\n",
    "#    #n=20\n",
    "#    #for j in range(len(HHat[:,i])-n+1):\n",
    "#    #    HHat[j,i]=np.mean(HHat[j:j+n,i])\n",
    "#    \n",
    "#    print((W[:,i]))\n",
    "#    plt.figure()\n",
    "#    plt.plot((W[:,i]))\n",
    "#    plt.figure()\n",
    "#    plt.plot(HHat[:,i])\n",
    "#    \n",
    "#for i in range(nrOfDrums):\n",
    "#    plt.figure()\n",
    "#    A=np.outer(W[i],HHat.T[i])\n",
    "#    plt.imshow(A, aspect='auto', origin='lower')\n",
    "#    \n",
    "### tee list_X ja list_y täsä drumseista.\n",
    "\n",
    "for i in drums:\n",
    "    #one for every template the drum has stored\n",
    "    for j in i.get_templates():\n",
    "        #one for every drum present in the template\n",
    "        a=np.ravel(i.get_name())\n",
    "        for k in range(len(a)):\n",
    "            list_X.append(j)\n",
    "            list_y.append(a[k])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##Classify all the templates so that precision is 1, and set the PROBABILITY_THRESHOLD accordingly.\n",
    "\n",
    "'''Tänne generator NN keras, joka oppii sitä mukaa ku roinaa tulee'''\n",
    "'''Eka opetellaan haitsun poljenta joka toimii käyttöliittymän osana'''\n",
    "'''Sit eri rummut'''\n",
    "'''Sit aletaan skabaamaan ja soittajan pätkät analysoidaan, muutetaan midiksi ja niistä sit opitaan generoimaan uutta'''\n",
    "\n",
    "#Tää jäi siihen että sai jotenkuten sn,bd,hh eroamaan, mutta jotain mätää on filttereissä kun basari ja snare on melkein samaa aaltoa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import sgd as SGD\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Convolution2D, Convolution1D, GRU, LSTM,BatchNormalization\n",
    "from keras.layers import MaxPooling2D, MaxPooling1D, AveragePooling2D\n",
    "from keras.layers import Flatten, Input\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "from os import listdir\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "n_samples=2**14\n",
    "\n",
    "#n_samples=len(list_y)\n",
    "#bootsrap extra samples by resampling with replacement\n",
    "\n",
    "#X,y=resample(np.array(list_X),np.array(list_y),n_samples=n_samples)\n",
    "#scaler=preprocessing.MinMaxScaler()\n",
    "#X=scaler.fit_transform(X)\n",
    "#X_train, y_train = X[:n_samples*0.8], y[:n_samples*0.8]\n",
    "#X_train_valid, y_train_valid = X[:n_samples*0.9], y[:n_samples*0.9]\n",
    "#X_valid, y_valid = X[n_samples*0.8:n_samples*0.9], y[n_samples*0.8:n_samples*0.9]\n",
    "#X_test, y_test = X[n_samples*0.9:], y[n_samples*0.9:]\n",
    "#n_samples=len(list_y)\n",
    "#bootsrap extra samples by resampling with replacement\n",
    "X,y=resample(np.array(list_X),np.array(list_y), n_samples=n_samples)\n",
    "#X,y=resample(np.array(list_X),np.array(list_y),replace=False)\n",
    "#X_train,y_train=resample(np.array(X[:int(n_samples*0.9)]),np.array(y[:int(n_samples*0.9)]),n_samples=n_samples*10)\n",
    "scaler=preprocessing.MinMaxScaler()\n",
    "X_train=scaler.fit_transform(X)\n",
    "#X_train=X\n",
    "#print(X_train.shape)\n",
    "y_train=y\n",
    "#X_train, y_train = X[:n_samples*0.8], y[:n_samples*0.8]\n",
    "#X_train_valid, y_train_valid = X[:n_samples*0.9], y[:n_samples*0.9]\n",
    "#X_valid, y_valid = X[n_samples*0.8:n_samples*0.9], y[n_samples*0.8:n_samples*0.9]\n",
    "#X_test, y_test = X[n_samples*0.9:], y[n_samples*0.9:]\n",
    "#X_test, y_test = resample(np.array(X[int(n_samples*0.9):]),np.array(y[int(n_samples*0.9):]),n_samples=n_samples)\n",
    "#X_test=scaler.fit_transform(X_test)\n",
    "y_train=keras.utils.np_utils.to_categorical(y_train)\n",
    "#y_test=keras.utils.np_utils.to_categorical(y_test)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "num_labels = y_train.shape[1]\n",
    "model = Sequential()\n",
    "act = ELU(input_shape=(X_train.shape[1],))\n",
    "# model.add(Dropout(0.2, input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(196, input_shape=(X_train.shape[1],), init='he_normal'))\n",
    "# model.add(act)\n",
    "model.add(Dropout(0.7))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, init='he_normal', activation='relu'))\n",
    "# model.add(act)\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, init='lecun_uniform', activation='relu'))\n",
    "# model.add(act)\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(64, init='normal', activation='sigmoid'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_labels, init='lecun_uniform', activation=\"softmax\"))\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "print(model.summary())\n",
    "\n",
    "t0=time()\n",
    "modelsaver=ModelCheckpoint(filepath=\"weights_testivedot.hdf5\", verbose=1, save_best_only=True)\n",
    "earlystopper=EarlyStopping(monitor=\"val_loss\", patience=40, mode='auto')\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='nadam')\n",
    "model.fit(X_train, y_train,batch_size=1024, nb_epoch=200\n",
    "          , callbacks=[modelsaver,earlystopper]\n",
    "          ,validation_split=0.1\n",
    "          #,validation_data=(X_test, y_test)\n",
    "          ,verbose=2)\n",
    "model.load_weights(\"weights_testivedot.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    "#preds = model.predict(X_val)\n",
    "model.save('keras.model_testivedot.h5')\n",
    "cnn=model\n",
    "print('Model saved to disk.')\n",
    "print ('Model buiding time:%0.2f' %(time()-t0))\n",
    "t0=time()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
